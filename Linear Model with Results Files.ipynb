{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_files(comp_chart_path, results_path):\n",
    "    '''\n",
    "        Will grab the .2 file from each comprehensive chart directory\n",
    "        \n",
    "        Args:\n",
    "            comp_chart_path (string): path to the comprehensive chart directories\n",
    "            results_path (string): path to directory in which to save results files\n",
    "            \n",
    "        Returns:\n",
    "            Nothing        \n",
    "    '''\n",
    "    chart_files = []\n",
    "    for subdir, dirs, files in os.walk(comp_chart_path):\n",
    "        for file in files:\n",
    "            if file[-1] == '2':\n",
    "                chart_files.append(subdir + '/' +file)\n",
    "       \n",
    "    # Delete files in results directory\n",
    "    \n",
    "    # Copy files\n",
    "    for file in chart_files:\n",
    "        shutil.copy(file, results_path)\n",
    "            \n",
    "create_results_files('./comp_chart_files/', './results_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Add date to input file name\\ninput_path = \\'./drf/\\'\\ninput_files = [input_path + file for file in os.listdir(input_path) if file.endswith(\".DRF\")]\\n\\n\\nfor file in input_files:\\n    new_name = file[6:-4] + \\'2018.DRF\\'\\n    shutil.copy(file, \\'./temp/{}\\'.format(new_name))\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Add date to input file name\n",
    "input_path = './drf/'\n",
    "input_files = [input_path + file for file in os.listdir(input_path) if file.endswith(\".DRF\")]\n",
    "\n",
    "\n",
    "for file in input_files:\n",
    "    new_name = file[6:-4] + '2018.DRF'\n",
    "    shutil.copy(file, './temp/{}'.format(new_name))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find All Pairs of Input/Results Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_pairs(input_path, results_path):\n",
    "    '''\n",
    "        Find matching input/output files\n",
    "        \n",
    "        Args:\n",
    "            input_path (string): relative path to input files\n",
    "            results_path (string): relative path to results files\n",
    "            \n",
    "        Returns:\n",
    "            (list) list of (input_file,results_file) pairs\n",
    "    '''\n",
    "    \n",
    "    # Get a list of all input files and results files\n",
    "    input_files = [input_path + file for file in os.listdir(input_path) if file.endswith(\".DRF\")]\n",
    "    results_files = [results_path + file for file in os.listdir(results_path) if file.endswith('.2')]\n",
    "    \n",
    "    # Get names of files w/o directories/extensions\n",
    "    input_names = sorted([file[len(input_path) : -4] for file in input_files])\n",
    "    results_names = sorted([file[len(results_path) : -2] for file in results_files])\n",
    "    \n",
    "    # Find matches \n",
    "    matches = [name for name in input_names if name in results_names]\n",
    "    \n",
    "    # Create list of input/results file pairs -- [(input_file, results_file),(...),...]\n",
    "    file_pairs = [('{}{}.DRF'.format(input_path, name), '{}{}.2'.format(results_path, name)) for name in matches]\n",
    "    \n",
    "    return file_pairs\n",
    "\n",
    "file_pairs = find_file_pairs(input_path='./input_files/', results_path='./results_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Number of Entrants to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entrants(input_file, results_file):\n",
    "    '''\n",
    "        Find highest post position for each race and use as number of entrants\n",
    "        \n",
    "        Args:\n",
    "            file (string): path to results file\n",
    "            \n",
    "        Returns:\n",
    "            Nothing\n",
    "    '''\n",
    "    # Load files \n",
    "    input_df = pd.read_csv(input_file, header=None)\n",
    "    res_df = pd.read_csv(results_file, header=None)\n",
    "    \n",
    "    # Find how many races are in each\n",
    "    race_col = 2\n",
    "    num_input_races = input_df[race_col].max()\n",
    "    num_res_races = res_df[race_col].max()\n",
    "    \n",
    "    # TODO: Assert that race counts are equal\n",
    "        \n",
    "    # For each race, count entrants, append as last column\n",
    "    input_last_col = input_df.columns.max() + 1\n",
    "    race_entrants = {}\n",
    "    for race in range(1,num_input_races+1):\n",
    "        entrants = input_df.loc[input_df[race_col] == race].shape[0]\n",
    "        iloc = input_df.loc[input_df[race_col] == race].index\n",
    "        input_df.loc[iloc, input_last_col] = pd.Series(entrants, index=iloc)\n",
    "        race_entrants[race] = entrants\n",
    "        \n",
    "    # Apply those same entrants numbers to results file\n",
    "    res_last_col = res_df.columns.max() + 1\n",
    "    for race in range(1, num_res_races+1):\n",
    "        iloc = res_df.loc[res_df[race_col] == race].index\n",
    "        res_df.loc[iloc, res_last_col] = pd.Series(race_entrants[race], index=iloc)\n",
    "        \n",
    "    # Save back to file\n",
    "    input_df.to_csv(input_file, header=False, index=False)\n",
    "    res_df.to_csv(results_file, header=False, index=False)\n",
    "\n",
    "    \n",
    "# Iterate through all files in file_pairs and add number of entrants\n",
    "for pair in file_pairs:\n",
    "    input_file = pair[0]\n",
    "    res_file = pair[1]\n",
    "    add_entrants(input_file, res_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Input and Results Files for Relevant Fields\n",
    "These fields do not include past performance data -- these past performance fields will be handled by a separate process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps for input/results file structures -- colnum:colname\n",
    "input_map = OrderedDict({\n",
    "        1: 'date',\n",
    "        2: 'race_num',\n",
    "        3: 'post_pos',\n",
    "        1435: 'num_entrants',\n",
    "        44: 'horse_name',\n",
    "        855: 'last_speed_rating',\n",
    "        216: 'speed_par',\n",
    "        33: 'app_weight_alw',\n",
    "        100: 'lt_earnings',\n",
    "        43: 'ml_odds',\n",
    "        28: 'trainer_starts',\n",
    "        29: 'trainer_wins',\n",
    "        34: 'jockey_starts',\n",
    "        35: 'jockey_wins'\n",
    "    })\n",
    "\n",
    "results_map = OrderedDict({\n",
    "    1: 'date',\n",
    "    2: 'race_num',\n",
    "    4: 'horse_name',\n",
    "    59: 'finish_pos', \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>post_pos</th>\n",
       "      <th>lt_earnings</th>\n",
       "      <th>app_weight_alw</th>\n",
       "      <th>ml_odds</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>jockey_starts</th>\n",
       "      <th>jockey_wins</th>\n",
       "      <th>last_speed_rating</th>\n",
       "      <th>speed_par</th>\n",
       "      <th>num_entrants</th>\n",
       "      <th>trainer_starts</th>\n",
       "      <th>trainer_wins</th>\n",
       "      <th>finish_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>37294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>134484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num  post_pos  lt_earnings  app_weight_alw  ml_odds  \\\n",
       "0  20180506         1         1        31833             NaN      3.0   \n",
       "1  20180506         1         2        22706             NaN      1.6   \n",
       "2  20180506         1         3        37294             NaN      2.5   \n",
       "3  20180506         1         4        39885             NaN      4.5   \n",
       "4  20180506         1         5       134484             NaN      2.0   \n",
       "\n",
       "           horse_name  jockey_starts  jockey_wins  last_speed_rating  \\\n",
       "0        ITZ ALL GOOD              0            0               98.0   \n",
       "1       STEEL PATRIOT              0            0               96.0   \n",
       "2           DM AURORA              0            0               92.0   \n",
       "3  ROUGE RIVER CARTEL              0            0               94.0   \n",
       "4    RECKLESS AN WILD              0            0               97.0   \n",
       "\n",
       "   speed_par  num_entrants  trainer_starts  trainer_wins  finish_pos  \n",
       "0        NaN           5.0               0             0         1.0  \n",
       "1        NaN           5.0               0             0         4.0  \n",
       "2        NaN           5.0               0             0         2.0  \n",
       "3        NaN           5.0               0             0         5.0  \n",
       "4        NaN           5.0               0             0         3.0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.DataFrame()\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for pair in file_pairs:\n",
    "    #Get input/results file names\n",
    "    input_file = pair[0]\n",
    "    results_file = pair[1]\n",
    "    \n",
    "    # Open files to dataframe -- Take only columns that are necessary\n",
    "    input_cols = [k for k in input_map.keys()]\n",
    "    results_cols = [k for k in results_map.keys()]\n",
    "    input_tmp = pd.read_csv(input_file, header=None)[input_cols]\n",
    "    results_tmp = pd.read_csv(results_file, header=None)[results_cols]\n",
    "    \n",
    "    # Rename cols\n",
    "    input_tmp.columns = [input_map[col] for col in input_tmp.columns]\n",
    "    results_tmp.columns = [results_map[col] for col in results_tmp.columns]\n",
    "    \n",
    "    # Add these inputs/results to dataframes\n",
    "    input_df = input_df.append(input_tmp)\n",
    "    results_df = results_df.append(results_tmp)\n",
    "    \n",
    "# Merge input and results dfs together -- convert horse_name to upper for results\n",
    "results_df['horse_name'] = results_df['horse_name'].apply(lambda x: str(x).upper())\n",
    "master_df = pd.merge(input_df, results_df,\n",
    "                     how='left', left_on=['date', 'race_num', 'horse_name'],\n",
    "                     right_on=['date','race_num', 'horse_name'])\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>post_pos</th>\n",
       "      <th>lt_earnings</th>\n",
       "      <th>app_weight_alw</th>\n",
       "      <th>ml_odds</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>last_speed_rating</th>\n",
       "      <th>speed_par</th>\n",
       "      <th>num_entrants</th>\n",
       "      <th>finish_pos</th>\n",
       "      <th>jockey_win_pct</th>\n",
       "      <th>trainer_win_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>37294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>134484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num  post_pos  lt_earnings  app_weight_alw  ml_odds  \\\n",
       "0  20180506         1         1        31833             0.0      3.0   \n",
       "1  20180506         1         2        22706             0.0      1.6   \n",
       "2  20180506         1         3        37294             0.0      2.5   \n",
       "3  20180506         1         4        39885             0.0      4.5   \n",
       "4  20180506         1         5       134484             0.0      2.0   \n",
       "\n",
       "           horse_name  last_speed_rating  speed_par  num_entrants  finish_pos  \\\n",
       "0        ITZ ALL GOOD               98.0        0.0           5.0         1.0   \n",
       "1       STEEL PATRIOT               96.0        0.0           5.0         4.0   \n",
       "2           DM AURORA               92.0        0.0           5.0         2.0   \n",
       "3  ROUGE RIVER CARTEL               94.0        0.0           5.0         5.0   \n",
       "4    RECKLESS AN WILD               97.0        0.0           5.0         3.0   \n",
       "\n",
       "   jockey_win_pct  trainer_win_pct  \n",
       "0             0.0              0.0  \n",
       "1             0.0              0.0  \n",
       "2             0.0              0.0  \n",
       "3             0.0              0.0  \n",
       "4             0.0              0.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_jockey_win_pct(df):\n",
    "    df['jockey_win_pct'] = df['jockey_wins'] / df['jockey_starts']\n",
    "    return df.drop(['jockey_wins', 'jockey_starts'], axis=1)\n",
    "\n",
    "def get_trainer_win_pct(df):\n",
    "    df['trainer_win_pct'] = df['trainer_wins'] / df['trainer_starts']\n",
    "    return df.drop(['trainer_wins', 'trainer_starts'], axis=1)\n",
    "\n",
    "# Calculate jockey/trainer win percentages\n",
    "master_df = get_jockey_win_pct(master_df)\n",
    "master_df = get_trainer_win_pct(master_df)\n",
    "\n",
    "# Clean NaN cols\n",
    "master_df = master_df.fillna(value=0)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Past Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map for past performance fields\n",
    "input_keys = OrderedDict({\n",
    "    1: 'date',\n",
    "    2: 'race_num',\n",
    "    44: 'horse_name',\n",
    "})\n",
    "\n",
    "input_pp_map = OrderedDict({\n",
    "    615 : 'pp_finish_pos',\n",
    "    345 : 'pp_num_entrants',\n",
    "    5: 'todays_distance',\n",
    "    315: 'pp_distance',\n",
    "    #535 : 'pp_race_class',\n",
    "    255 : 'pp_race_date',\n",
    "    1045: 'pp_claimed',\n",
    "    1125: 'pp_favorite',\n",
    "    605: 'pp_stretch_pos',\n",
    "    113: 'pp_workout_time',\n",
    "    465: 'pp_winners_margin'\n",
    "})\n",
    "\n",
    "#name_to_pp_col = OrderedDict({v:k for k,v in input_pp_map.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>pp_race_date_1</th>\n",
       "      <th>pp_race_date_2</th>\n",
       "      <th>todays_distance_0</th>\n",
       "      <th>todays_distance_1</th>\n",
       "      <th>todays_distance_2</th>\n",
       "      <th>pp_winners_margin_0</th>\n",
       "      <th>pp_winners_margin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_finish_pos_1</th>\n",
       "      <th>pp_finish_pos_2</th>\n",
       "      <th>pp_favorite_2</th>\n",
       "      <th>pp_workout_time_0</th>\n",
       "      <th>pp_workout_time_1</th>\n",
       "      <th>pp_workout_time_2</th>\n",
       "      <th>pp_distance_0</th>\n",
       "      <th>pp_distance_1</th>\n",
       "      <th>pp_distance_2</th>\n",
       "      <th>pp_race_date_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>20171016.0</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>220.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>20171009.0</td>\n",
       "      <td>20170911.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>20171009.0</td>\n",
       "      <td>20170925.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20171023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>20170918.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>400.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>20170720.0</td>\n",
       "      <td>20161017.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>350.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>20170810.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num          horse_name  pp_race_date_1  pp_race_date_2  \\\n",
       "0  20180506         1        ITZ ALL GOOD      20171016.0      20171002.0   \n",
       "1  20180506         1       STEEL PATRIOT      20171009.0      20170911.0   \n",
       "2  20180506         1           DM AURORA      20171009.0      20170925.0   \n",
       "3  20180506         1  ROUGE RIVER CARTEL      20171002.0      20170918.0   \n",
       "4  20180506         1    RECKLESS AN WILD      20170720.0      20161017.0   \n",
       "\n",
       "   todays_distance_0 todays_distance_1  todays_distance_2  \\\n",
       "0                300                 D                NaN   \n",
       "1                300                 D                NaN   \n",
       "2                300                 D                NaN   \n",
       "3                300                 D                NaN   \n",
       "4                300                 D                NaN   \n",
       "\n",
       "   pp_winners_margin_0  pp_winners_margin_1      ...        pp_finish_pos_1  \\\n",
       "0                 0.75                 0.25      ...                      2   \n",
       "1                 0.25                 0.25      ...                      7   \n",
       "2                 0.75                 0.13      ...                      4   \n",
       "3                 0.25                 0.50      ...                      5   \n",
       "4                 0.50                 0.50      ...                      1   \n",
       "\n",
       "  pp_finish_pos_2 pp_favorite_2 pp_workout_time_0  pp_workout_time_1  \\\n",
       "0               4           0.0              13.2               13.6   \n",
       "1               1           0.0              13.8               13.2   \n",
       "2               6           0.0              12.6               12.4   \n",
       "3               3           0.0              13.4              -12.2   \n",
       "4               4           0.0              12.6               13.4   \n",
       "\n",
       "   pp_workout_time_2  pp_distance_0 pp_distance_1 pp_distance_2 pp_race_date_0  \n",
       "0               13.2          220.0         300.0         350.0     20171030.0  \n",
       "1               12.0          400.0         440.0         330.0     20171030.0  \n",
       "2              -13.2          350.0         350.0         300.0     20171023.0  \n",
       "3               13.2          400.0         350.0         330.0     20171030.0  \n",
       "4               13.2          350.0         330.0         350.0     20170810.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_past_performance_data(input_files, num_races=3):\n",
    "    '''\n",
    "        Go through input files and get past performance data\n",
    "        \n",
    "        Args: \n",
    "            input_files (list): list of input file names \n",
    "            num_races (int): number of races back to grab data for\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame with past performance data for each horse\n",
    "    '''\n",
    "    pp_df = pd.DataFrame()\n",
    "    \n",
    "    # Create new mapping for this number of races\n",
    "    updated_pp_map = OrderedDict({k+race:'{}_{}'.format(v, race) for k,v in input_pp_map.items() for race in range(num_races)})\n",
    "    \n",
    "    for file in input_files:\n",
    "        # Open input file to df\n",
    "        df = pd.read_csv(file, header=None)\n",
    "        \n",
    "        # Only include key/past performance columns\n",
    "        incl_cols = list(input_keys.keys()) + list(updated_pp_map.keys())\n",
    "        df = df[incl_cols]\n",
    "        \n",
    "        # Rename columns\n",
    "        renamed_cols = []\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                # PP Column\n",
    "                rn_col = updated_pp_map[col]\n",
    "            except:\n",
    "                # Key Column \n",
    "                rn_col = input_keys[col]    \n",
    "            renamed_cols.append(rn_col)\n",
    "        df.columns = renamed_cols\n",
    "        \n",
    "        # Append this file's df to pp_df\n",
    "        pp_df = pp_df.append(df)\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "input_files = [pair[0] for pair in file_pairs]\n",
    "num_races = 3\n",
    "pp_df = get_past_performance_data(input_files, num_races)\n",
    "pp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Past Performance DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>pp_race_date_1</th>\n",
       "      <th>pp_race_date_2</th>\n",
       "      <th>todays_distance_0</th>\n",
       "      <th>todays_distance_1</th>\n",
       "      <th>todays_distance_2</th>\n",
       "      <th>pp_winners_margin_0</th>\n",
       "      <th>pp_winners_margin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_finish_pos_1</th>\n",
       "      <th>pp_finish_pos_2</th>\n",
       "      <th>pp_favorite_2</th>\n",
       "      <th>pp_workout_time_0</th>\n",
       "      <th>pp_workout_time_1</th>\n",
       "      <th>pp_workout_time_2</th>\n",
       "      <th>pp_distance_0</th>\n",
       "      <th>pp_distance_1</th>\n",
       "      <th>pp_distance_2</th>\n",
       "      <th>pp_race_date_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>20171016.0</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>220.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>20171009.0</td>\n",
       "      <td>20170911.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>20171009.0</td>\n",
       "      <td>20170925.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20171023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>20170918.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>400.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>20170720.0</td>\n",
       "      <td>20161017.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>350.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>20170810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>TOO MUCH WHITE</td>\n",
       "      <td>20170918.0</td>\n",
       "      <td>20170813.0</td>\n",
       "      <td>220</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>20171023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>JESS RIP</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>20170903.0</td>\n",
       "      <td>220</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>350.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>JUNOIMZOOMIN</td>\n",
       "      <td>20170723.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>FLIRT WITH THE BOYZ</td>\n",
       "      <td>20170918.0</td>\n",
       "      <td>20170827.0</td>\n",
       "      <td>220</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>250.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>GEORGIES MAY KITTY</td>\n",
       "      <td>20171016.0</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>220</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20171030.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num           horse_name  pp_race_date_1  pp_race_date_2  \\\n",
       "0  20180506         1         ITZ ALL GOOD      20171016.0      20171002.0   \n",
       "1  20180506         1        STEEL PATRIOT      20171009.0      20170911.0   \n",
       "2  20180506         1            DM AURORA      20171009.0      20170925.0   \n",
       "3  20180506         1   ROUGE RIVER CARTEL      20171002.0      20170918.0   \n",
       "4  20180506         1     RECKLESS AN WILD      20170720.0      20161017.0   \n",
       "5  20180506         2       TOO MUCH WHITE      20170918.0      20170813.0   \n",
       "6  20180506         2             JESS RIP      20171002.0      20170903.0   \n",
       "7  20180506         2         JUNOIMZOOMIN      20170723.0             NaN   \n",
       "8  20180506         2  FLIRT WITH THE BOYZ      20170918.0      20170827.0   \n",
       "9  20180506         2   GEORGIES MAY KITTY      20171016.0      20171002.0   \n",
       "\n",
       "   todays_distance_0 todays_distance_1  todays_distance_2  \\\n",
       "0                300                 D                NaN   \n",
       "1                300                 D                NaN   \n",
       "2                300                 D                NaN   \n",
       "3                300                 D                NaN   \n",
       "4                300                 D                NaN   \n",
       "5                220                 D                NaN   \n",
       "6                220                 D                NaN   \n",
       "7                220                 D                NaN   \n",
       "8                220                 D                NaN   \n",
       "9                220                 D                NaN   \n",
       "\n",
       "   pp_winners_margin_0  pp_winners_margin_1       ...        pp_finish_pos_1  \\\n",
       "0                 0.75                 0.25       ...                      2   \n",
       "1                 0.25                 0.25       ...                      7   \n",
       "2                 0.75                 0.13       ...                      4   \n",
       "3                 0.25                 0.50       ...                      5   \n",
       "4                 0.50                 0.50       ...                      1   \n",
       "5                 0.13                 0.50       ...                     92   \n",
       "6                 2.00                 0.13       ...                      5   \n",
       "7                 0.50                 1.25       ...                      1   \n",
       "8                 0.13                 0.25       ...                      7   \n",
       "9                 2.00                 0.06       ...                      2   \n",
       "\n",
       "  pp_finish_pos_2 pp_favorite_2 pp_workout_time_0  pp_workout_time_1  \\\n",
       "0               4             0              13.2               13.6   \n",
       "1               1             0              13.8               13.2   \n",
       "2               6             0              12.6               12.4   \n",
       "3               3             0              13.4              -12.2   \n",
       "4               4             0              12.6               13.4   \n",
       "5               1             0              12.2               14.0   \n",
       "6               5             0             -12.2               12.4   \n",
       "7              92             0              13.8               15.2   \n",
       "8               4             0              13.2               12.6   \n",
       "9               3             0              13.6               12.8   \n",
       "\n",
       "   pp_workout_time_2  pp_distance_0  pp_distance_1  pp_distance_2  \\\n",
       "0               13.2          220.0          300.0          350.0   \n",
       "1               12.0          400.0          440.0          330.0   \n",
       "2              -13.2          350.0          350.0          300.0   \n",
       "3               13.2          400.0          350.0          330.0   \n",
       "4               13.2          350.0          330.0          350.0   \n",
       "5               13.8          350.0          400.0          330.0   \n",
       "6               13.6          350.0          250.0          300.0   \n",
       "7               13.6          330.0          330.0            NaN   \n",
       "8              -13.4          250.0          350.0          300.0   \n",
       "9               14.0          350.0          400.0          250.0   \n",
       "\n",
       "   pp_race_date_0  \n",
       "0      20171030.0  \n",
       "1      20171030.0  \n",
       "2      20171023.0  \n",
       "3      20171030.0  \n",
       "4      20170810.0  \n",
       "5      20171023.0  \n",
       "6      20171030.0  \n",
       "7      20170813.0  \n",
       "8      20171030.0  \n",
       "9      20171030.0  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_finish_pos_cols(pp_df, num_races=3):\n",
    "        # Get finish position column names\n",
    "        finish_pos_cols = ['pp_finish_pos_{}'.format(race) for race in range(num_races)]\n",
    "        \n",
    "        def clean_val(val):\n",
    "            # If value is numeric, return its integer rep\n",
    "            try:\n",
    "                return int(val)\n",
    "            except:\n",
    "                # If value not numeric, return 0 (did not finish)\n",
    "                return int(92)\n",
    "            \n",
    "        # Clean columns\n",
    "        for col in finish_pos_cols:\n",
    "            pp_df[col] = pp_df[col].apply(clean_val)\n",
    "            \n",
    "        return pp_df\n",
    "    \n",
    "def clean_stretch_pos_cols(pp_df, num_races=3):\n",
    "        # Get stretch position column names\n",
    "        stretch_pos_cols = ['pp_stretch_pos_{}'.format(race) for race in range(num_races)]\n",
    "        \n",
    "        def clean_val(val):\n",
    "            # If value is numeric, return its integer rep\n",
    "            try:\n",
    "                return int(val)\n",
    "            except:\n",
    "                # If value not numeric, return 92 (did not finish)\n",
    "                return int(92)\n",
    "            \n",
    "        \n",
    "        # Clean columns\n",
    "        for col in stretch_pos_cols:\n",
    "            pp_df[col] = pp_df[col].apply(clean_val)\n",
    "            \n",
    "        return pp_df\n",
    "    \n",
    "def clean_favorite_cols(pp_df, num_races=3):\n",
    "    def conv(val):\n",
    "        if math.isnan(val):\n",
    "            return int(0)\n",
    "        else:\n",
    "            return int(val)\n",
    "        \n",
    "    # Get favorite column names\n",
    "    favorite_columns = ['pp_favorite_{}'.format(race) for race in range(num_races)]\n",
    "    \n",
    "    # Convert to integers\n",
    "    for col in favorite_columns:\n",
    "        pp_df[col] = pp_df[col].apply(conv)\n",
    "        \n",
    "    return pp_df\n",
    "    \n",
    "    \n",
    "def clean_pp_df(pp_df, num_races=3):\n",
    "    '''\n",
    "        Clean fields in pp_df\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): dataframe to clean\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame) cleaned version of pp_df\n",
    "    '''\n",
    "    pp_df = clean_finish_pos_cols(pp_df, num_races)\n",
    "    pp_df = clean_stretch_pos_cols(pp_df, num_races)\n",
    "    pp_df = clean_favorite_cols(pp_df, num_races)\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "pp_df = clean_pp_df(pp_df, num_races)\n",
    "pp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive Past Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>pp_race_date_1</th>\n",
       "      <th>pp_race_date_2</th>\n",
       "      <th>todays_distance_0</th>\n",
       "      <th>todays_distance_1</th>\n",
       "      <th>todays_distance_2</th>\n",
       "      <th>pp_winners_margin_0</th>\n",
       "      <th>pp_winners_margin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>raw_pp_finish_pos_1</th>\n",
       "      <th>raw_pp_finish_pos_2</th>\n",
       "      <th>imp_finish_pos</th>\n",
       "      <th>recent_race</th>\n",
       "      <th>was_claimed</th>\n",
       "      <th>was_favorite</th>\n",
       "      <th>improved_stretch_pos</th>\n",
       "      <th>had_bullet</th>\n",
       "      <th>won_by_margin</th>\n",
       "      <th>won_at_similar_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>20171016.0</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>20171009.0</td>\n",
       "      <td>20170911.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>20171009.0</td>\n",
       "      <td>20170925.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>20171002.0</td>\n",
       "      <td>20170918.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>20170720.0</td>\n",
       "      <td>20161017.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num          horse_name  pp_race_date_1  pp_race_date_2  \\\n",
       "0  20180506         1        ITZ ALL GOOD      20171016.0      20171002.0   \n",
       "1  20180506         1       STEEL PATRIOT      20171009.0      20170911.0   \n",
       "2  20180506         1           DM AURORA      20171009.0      20170925.0   \n",
       "3  20180506         1  ROUGE RIVER CARTEL      20171002.0      20170918.0   \n",
       "4  20180506         1    RECKLESS AN WILD      20170720.0      20161017.0   \n",
       "\n",
       "   todays_distance_0 todays_distance_1  todays_distance_2  \\\n",
       "0                300                 D                NaN   \n",
       "1                300                 D                NaN   \n",
       "2                300                 D                NaN   \n",
       "3                300                 D                NaN   \n",
       "4                300                 D                NaN   \n",
       "\n",
       "   pp_winners_margin_0  pp_winners_margin_1         ...           \\\n",
       "0                 0.75                 0.25         ...            \n",
       "1                 0.25                 0.25         ...            \n",
       "2                 0.75                 0.13         ...            \n",
       "3                 0.25                 0.50         ...            \n",
       "4                 0.50                 0.50         ...            \n",
       "\n",
       "   raw_pp_finish_pos_1 raw_pp_finish_pos_2 imp_finish_pos recent_race  \\\n",
       "0                    2                   4           True       False   \n",
       "1                    7                   1           True       False   \n",
       "2                    4                   6          False       False   \n",
       "3                    5                   3          False       False   \n",
       "4                    1                   4           True       False   \n",
       "\n",
       "   was_claimed  was_favorite  improved_stretch_pos  had_bullet  won_by_margin  \\\n",
       "0        False         False                 False       False           True   \n",
       "1        False          True                 False       False           True   \n",
       "2        False         False                 False       False           True   \n",
       "3        False         False                 False       False           True   \n",
       "4        False          True                  True       False           True   \n",
       "\n",
       "   won_at_similar_dist  \n",
       "0                 True  \n",
       "1                 True  \n",
       "2                 True  \n",
       "3                 True  \n",
       "4                 True  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_improved_finish_pos(pp_df, num_races=3):\n",
    "    '''\n",
    "        Calculate if horse is improving its finish position over the past races\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame) an updated version of pp_df with a column for improved\n",
    "            finish position\n",
    "    '''\n",
    "    \n",
    "    def all_seq_vals_less_than_one(seq):\n",
    "        ''' Returns true if all values in the passed sequence are <=1 '''\n",
    "        for elt in seq:\n",
    "            if elt > 1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Get past finish pos cols\n",
    "    finish_pos_cols = ['pp_finish_pos_{}'.format(race) for race in range(num_races)]\n",
    "    # Concat all finish positions for each horse in a sequential list starting with most\n",
    "    # recent race \n",
    "    finish_pos_seqs = pp_df[finish_pos_cols].values.tolist()\n",
    "    \n",
    "    imp_finish_pos = []\n",
    "    for seq in finish_pos_seqs:\n",
    "        # Skip any sequence where NaN appears\n",
    "        if np.nan in seq:\n",
    "            imp_finish_pos.append(False)\n",
    "        # Skip any seq where horse didn't finish (fractional finish pos > 1)\n",
    "        elif not all_seq_vals_less_than_one(seq):\n",
    "            imp_finish_pos.append(False)\n",
    "        else:\n",
    "            # Determine if last finish was better than previous average finish\n",
    "            most_recent = seq[0]\n",
    "            avg_prev_finish = np.mean(seq[1:])\n",
    "            imp_finish_pos.append(most_recent < avg_prev_finish)\n",
    "            \n",
    "    # Assign improved finish position series to pp_df\n",
    "    pp_df['imp_finish_pos'] = pd.Series(imp_finish_pos)\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "def get_recent_race(pp_df, threshold=21):\n",
    "    '''\n",
    "        Determine if a horse has had a previous race within threshold days\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            threshold (int): days to look back\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame) updated pp_df containing bool column stating whether\n",
    "            each horse had a recent race or not\n",
    "    '''\n",
    "    \n",
    "    def conv_date(val):\n",
    "        # Set NaNs to 1970\n",
    "        if math.isnan(float(val)):\n",
    "            val = 19700101\n",
    "        val = str(int(val))\n",
    "        return datetime.strptime(val, '%Y%m%d')\n",
    "    \n",
    "    # Determine if race most recent race is within threshold\n",
    "    pp_df['today'] = pp_df['date'].apply(conv_date)\n",
    "    pp_df['last_race'] = pp_df['pp_race_date_0'].apply(conv_date)\n",
    "    pp_df['timedelta'] = pd.Series(timedelta(days=threshold), index=pp_df.index)\n",
    "    pp_df['cutoff'] = pp_df['today'] - pp_df['timedelta']\n",
    "    pp_df['recent_race'] = pp_df['cutoff'] <= pp_df['last_race'] # Cutoff happened before last race\n",
    "    \n",
    "    # Drop intermediate columns\n",
    "    drop_cols = ['today', 'last_race', 'timedelta', 'cutoff']\n",
    "    return pp_df.drop(drop_cols, axis=1)\n",
    "    \n",
    "def get_past_finish_pos(pp_df, num_races=3):\n",
    "    '''\n",
    "        Calculate previous finish positions as finish_pos/num_entrants\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame) past performance dataframe\n",
    "            num_races (int): number of races for which we have past performance\n",
    "        \n",
    "        Returns:\n",
    "            (pd.DataFrame) updated pp_df with finish positions calculated\n",
    "    '''\n",
    "    # Get finish position/entrants columns names\n",
    "    finish_pos_cols = ['pp_finish_pos_{}'.format(race) for race in range(num_races)]\n",
    "    entrants_cols = ['pp_num_entrants_{}'.format(race) for race in range(num_races)]\n",
    "    cols = list(zip(finish_pos_cols, entrants_cols))\n",
    "    \n",
    "    # Divide finish pos by num entrants, save a raw copy of finish position\n",
    "    for f_col, e_col in cols:\n",
    "        pp_df['raw_'+f_col] = pp_df[f_col]\n",
    "        pp_df[f_col] = pp_df[f_col] / pp_df[e_col]\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "def get_claimed_in_past(pp_df, num_races=3):\n",
    "    '''\n",
    "        Determine if a horse was claimed in the past num_races\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame) updated version of pp_df\n",
    "    '''\n",
    "    # Claimed column names\n",
    "    claimed_cols = ['pp_claimed_{}'.format(race) for race in range(num_races)]\n",
    "    claimed_seqs = pp_df[claimed_cols].values.tolist()\n",
    "    \n",
    "    # Determine if claimed in recent races    \n",
    "    claimed = [True if 'c' in seq else False for seq in claimed_seqs]\n",
    "    \n",
    "    # Assign to pp_df\n",
    "    pp_df['was_claimed'] = pd.Series(claimed, index=pp_df.index)\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "def was_favorite(pp_df, num_races=3):\n",
    "    '''\n",
    "        Determine if a horse was the favorite in any of its recent races\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "    '''\n",
    "    # Get favorite columns\n",
    "    favorite_cols = ['pp_favorite_{}'.format(race) for race in range(num_races)]\n",
    "    favorite_seqs = pp_df[favorite_cols].values.tolist()\n",
    "    \n",
    "    # If 1 in sequence, horse was favorite in recent race\n",
    "    was_favorite = [True if 1 in seq else False for seq in favorite_seqs]\n",
    "    \n",
    "    pp_df['was_favorite'] = pd.Series(was_favorite, index=pp_df.index)\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "def improved_stretch_pos(pp_df, num_races=3):\n",
    "    '''\n",
    "        Determine if a horse improved its finish position down the stretch in the most\n",
    "        recent race\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "    '''\n",
    "    # Stretch position columns\n",
    "    stretch_pos_cols = ['pp_stretch_pos_{}'.format(race) for race in range(num_races)]\n",
    "    \n",
    "    # Get fractional stretch position\n",
    "    pp_df['pp_stretch_pos'] = pp_df['pp_stretch_pos_0'] / pp_df['pp_num_entrants_0']\n",
    "    \n",
    "    # Determine if stretch pos > finish pos\n",
    "    pp_df['improved_stretch_pos'] = pp_df['pp_stretch_pos'] > pp_df['pp_finish_pos_0']\n",
    "    \n",
    "    return pp_df.drop(['pp_stretch_pos'], axis=1)\n",
    "\n",
    "def had_bullet_workout(pp_df, num_races=3):\n",
    "    '''\n",
    "        Determine if a horse had a bullet workout in previous workout\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "    '''\n",
    "    # Get workout time columns\n",
    "    workout_cols = ['pp_workout_time_{}'.format(race) for race in range(num_races)]\n",
    "    \n",
    "    # Determine if last workout was bullet\n",
    "    pp_df['had_bullet'] = pp_df['pp_workout_time_0'] < 0\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "def won_by_margin(pp_df, num_races=3, margin=5):\n",
    "    '''\n",
    "        Determine if a horse won last race by at least margin lengths\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "            margin (float): number of lengths by which horse had to win\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame) updated version of pp_df\n",
    "    '''\n",
    "    # Find all winners of last race\n",
    "    winners = pp_df.loc[pp_df.raw_pp_finish_pos_0 == 1]\n",
    "    \n",
    "    # Find all winners with at least margin length victory\n",
    "    big_winners = winners.loc[winners.pp_winners_margin_0 >= margin].index\n",
    "    \n",
    "    # Create new col, default to false. Set True for all horses in big_winners index\n",
    "    pp_df['won_by_margin'] = pd.Series(False, index=pp_df.index)\n",
    "    pp_df.loc[big_winners, 'won_by_margin'] = True\n",
    "    \n",
    "    return pp_df\n",
    "\n",
    "def won_at_similar_distance(pp_df, num_races=3):\n",
    "    '''\n",
    "        Determine if a horse won a recent race at the same distance as today's race\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame) updated version of pp_df\n",
    "    '''\n",
    "    # Get distance and finish pos cols\n",
    "    distance_cols = ['pp_distance_{}'.format(race) for race in range(num_races)]\n",
    "    raw_finish_cols = ['raw_pp_finish_pos_{}'.format(race) for race in range(num_races)]\n",
    "    \n",
    "    # Find winners at similar distance by iterating through each recent race\n",
    "    winners = []\n",
    "    for race in range(num_races):\n",
    "        dist_col = 'pp_distance_{}'.format(race)\n",
    "        finish_col = 'raw_pp_finish_pos_{}'.format(race)\n",
    "        today_dist_col = 'todays_distance_0'\n",
    "        \n",
    "        winners += pp_df.loc[(pp_df[dist_col] == pp_df[today_dist_col]) & (pp_df[finish_col] == 1)].index.tolist()\n",
    "        \n",
    "    # Create new column to denote if won at similar distance -- default False, True for \n",
    "    # horses in winners\n",
    "    pp_df['won_at_similar_dist'] = pd.Series(False, index=pp_df.index)\n",
    "    pp_df.loc[winners, 'won_at_similar_dist'] = True\n",
    "\n",
    "    return pp_df\n",
    "    \n",
    "def derive_pp_metrics(pp_df, num_races=3):\n",
    "    # Past Finish Positions\n",
    "    pp_df = get_past_finish_pos(pp_df, num_races)\n",
    "    # Improved Finish Position\n",
    "    pp_df = get_improved_finish_pos(pp_df, num_races)\n",
    "    # Recent race\n",
    "    pp_df = get_recent_race(pp_df, 21)\n",
    "    # Claimed in Past\n",
    "    pp_df = get_claimed_in_past(pp_df, num_races)\n",
    "    # Favorite in past\n",
    "    pp_df = was_favorite(pp_df, num_races)\n",
    "    # Improved stretch pos\n",
    "    pp_df = improved_stretch_pos(pp_df, num_races)\n",
    "    # Workout Rating\n",
    "    pp_df = had_bullet_workout(pp_df, num_races)\n",
    "    # Won last race by 5+ lengths\n",
    "    pp_df = won_by_margin(pp_df, num_races, margin=4)\n",
    "    # Won at similar distance\n",
    "    pp_df = won_at_similar_distance(pp_df, num_races)    \n",
    "    \n",
    "    return pp_df\n",
    "    \n",
    "pp_df = derive_pp_metrics(pp_df)\n",
    "pp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Intermediate Derivation Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>imp_finish_pos</th>\n",
       "      <th>recent_race</th>\n",
       "      <th>was_claimed</th>\n",
       "      <th>was_favorite</th>\n",
       "      <th>improved_stretch_pos</th>\n",
       "      <th>had_bullet</th>\n",
       "      <th>won_by_margin</th>\n",
       "      <th>won_at_similar_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num          horse_name  imp_finish_pos  recent_race  \\\n",
       "0  20180506         1        ITZ ALL GOOD            True        False   \n",
       "1  20180506         1       STEEL PATRIOT            True        False   \n",
       "2  20180506         1           DM AURORA           False        False   \n",
       "3  20180506         1  ROUGE RIVER CARTEL           False        False   \n",
       "4  20180506         1    RECKLESS AN WILD            True        False   \n",
       "\n",
       "   was_claimed  was_favorite  improved_stretch_pos  had_bullet  won_by_margin  \\\n",
       "0        False         False                 False       False           True   \n",
       "1        False          True                 False       False           True   \n",
       "2        False         False                 False       False           True   \n",
       "3        False         False                 False       False           True   \n",
       "4        False          True                  True       False           True   \n",
       "\n",
       "   won_at_similar_dist  \n",
       "0                 True  \n",
       "1                 True  \n",
       "2                 True  \n",
       "3                 True  \n",
       "4                 True  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_deriv_columns(pp_df, num_races=3):\n",
    "    '''\n",
    "        Drop all columns used as intermediates during feature derivation from pp_df\n",
    "        \n",
    "        Args:\n",
    "            pp_df (pd.DataFrame): past performance dataframe\n",
    "            num_races (int): number of races for which we have past performances\n",
    "            \n",
    "        Returns:\n",
    "            (pd.DataFrame): a cleaned version of pp_df\n",
    "    '''\n",
    "    column_dict = {\n",
    "        'claimed_cols' : ['pp_claimed_{}'.format(race) for race in range(num_races)],\n",
    "        'date_cols' : ['pp_race_date_{}'.format(race) for race in range(num_races)],\n",
    "        'distance_cols' : ['pp_distance_{}'.format(race) for race in range(num_races)],\n",
    "        'entrants_cols' : ['pp_num_entrants_{}'.format(race) for race in range(num_races)],   \n",
    "        'favorite_cols' : ['pp_favorite_{}'.format(race) for race in range(num_races)],\n",
    "        'finish_pos_cols' : ['pp_finish_pos_{}'.format(race) for race in range(num_races)],\n",
    "        'margin_cols' : ['pp_winners_margin_{}'.format(race) for race in range(num_races)],\n",
    "        'raw_finish_cols' : ['raw_pp_finish_pos_{}'.format(race) for race in range(num_races)],\n",
    "        'stretch_pos_cols' : ['pp_stretch_pos_{}'.format(race) for race in range(num_races)],\n",
    "        'todays_distance_cols' : ['todays_distance_{}'.format(race) for race in range(num_races)],\n",
    "        'workout_cols' : ['pp_workout_time_{}'.format(race) for race in range(num_races)],\n",
    "    }\n",
    "    \n",
    "    for k, cols in column_dict.items():\n",
    "        pp_df = pp_df.drop(cols, axis=1)\n",
    "        \n",
    "    return pp_df\n",
    "\n",
    "pp_df = clean_deriv_columns(pp_df, num_races)\n",
    "pp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Past Performance with Master DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>post_pos</th>\n",
       "      <th>lt_earnings</th>\n",
       "      <th>app_weight_alw</th>\n",
       "      <th>ml_odds</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>last_speed_rating</th>\n",
       "      <th>speed_par</th>\n",
       "      <th>num_entrants</th>\n",
       "      <th>...</th>\n",
       "      <th>jockey_win_pct</th>\n",
       "      <th>trainer_win_pct</th>\n",
       "      <th>imp_finish_pos</th>\n",
       "      <th>recent_race</th>\n",
       "      <th>was_claimed</th>\n",
       "      <th>was_favorite</th>\n",
       "      <th>improved_stretch_pos</th>\n",
       "      <th>had_bullet</th>\n",
       "      <th>won_by_margin</th>\n",
       "      <th>won_at_similar_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>37294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>134484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num  post_pos  lt_earnings  app_weight_alw  ml_odds  \\\n",
       "0  20180506         1         1        31833             0.0      3.0   \n",
       "1  20180506         1         2        22706             0.0      1.6   \n",
       "2  20180506         1         3        37294             0.0      2.5   \n",
       "3  20180506         1         4        39885             0.0      4.5   \n",
       "4  20180506         1         5       134484             0.0      2.0   \n",
       "\n",
       "           horse_name  last_speed_rating  speed_par  num_entrants  \\\n",
       "0        ITZ ALL GOOD               98.0        0.0           5.0   \n",
       "1       STEEL PATRIOT               96.0        0.0           5.0   \n",
       "2           DM AURORA               92.0        0.0           5.0   \n",
       "3  ROUGE RIVER CARTEL               94.0        0.0           5.0   \n",
       "4    RECKLESS AN WILD               97.0        0.0           5.0   \n",
       "\n",
       "          ...           jockey_win_pct  trainer_win_pct  imp_finish_pos  \\\n",
       "0         ...                      0.0              0.0            True   \n",
       "1         ...                      0.0              0.0            True   \n",
       "2         ...                      0.0              0.0           False   \n",
       "3         ...                      0.0              0.0           False   \n",
       "4         ...                      0.0              0.0            True   \n",
       "\n",
       "   recent_race  was_claimed  was_favorite  improved_stretch_pos  had_bullet  \\\n",
       "0        False        False         False                 False       False   \n",
       "1        False        False          True                 False       False   \n",
       "2        False        False         False                 False       False   \n",
       "3        False        False         False                 False       False   \n",
       "4        False        False          True                  True       False   \n",
       "\n",
       "   won_by_margin  won_at_similar_dist  \n",
       "0           True                 True  \n",
       "1           True                 True  \n",
       "2           True                 True  \n",
       "3           True                 True  \n",
       "4           True                 True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.merge(master_df, pp_df,\n",
    "                     how='left', left_on=['date', 'race_num', 'horse_name'],\n",
    "                     right_on=['date','race_num', 'horse_name'])\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race_num</th>\n",
       "      <th>post_pos</th>\n",
       "      <th>lt_earnings</th>\n",
       "      <th>app_weight_alw</th>\n",
       "      <th>ml_odds</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>last_speed_rating</th>\n",
       "      <th>speed_par</th>\n",
       "      <th>num_entrants</th>\n",
       "      <th>...</th>\n",
       "      <th>trainer_win_pct</th>\n",
       "      <th>imp_finish_pos</th>\n",
       "      <th>recent_race</th>\n",
       "      <th>was_claimed</th>\n",
       "      <th>was_favorite</th>\n",
       "      <th>improved_stretch_pos</th>\n",
       "      <th>had_bullet</th>\n",
       "      <th>won_by_margin</th>\n",
       "      <th>won_at_similar_dist</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ITZ ALL GOOD</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>STEEL PATRIOT</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>37294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DM AURORA</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ROUGE RIVER CARTEL</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180506</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>134484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RECKLESS AN WILD</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>TOO MUCH WHITE</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>JESS RIP</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>JUNOIMZOOMIN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>FLIRT WITH THE BOYZ</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20180506</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>22840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GEORGIES MAY KITTY</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  race_num  post_pos  lt_earnings  app_weight_alw  ml_odds  \\\n",
       "0  20180506         1         1        31833             0.0      3.0   \n",
       "1  20180506         1         2        22706             0.0      1.6   \n",
       "2  20180506         1         3        37294             0.0      2.5   \n",
       "3  20180506         1         4        39885             0.0      4.5   \n",
       "4  20180506         1         5       134484             0.0      2.0   \n",
       "5  20180506         2         1        28496             0.0      2.5   \n",
       "6  20180506         2         2         8292             0.0      3.5   \n",
       "7  20180506         2         3        14749             0.0      3.0   \n",
       "8  20180506         2         4        13662             0.0      5.0   \n",
       "9  20180506         2         5        22840             0.0     10.0   \n",
       "\n",
       "            horse_name  last_speed_rating  speed_par  num_entrants    ...     \\\n",
       "0         ITZ ALL GOOD               98.0        0.0           5.0    ...      \n",
       "1        STEEL PATRIOT               96.0        0.0           5.0    ...      \n",
       "2            DM AURORA               92.0        0.0           5.0    ...      \n",
       "3   ROUGE RIVER CARTEL               94.0        0.0           5.0    ...      \n",
       "4     RECKLESS AN WILD               97.0        0.0           5.0    ...      \n",
       "5       TOO MUCH WHITE               94.0        0.0           6.0    ...      \n",
       "6             JESS RIP               94.0        0.0           6.0    ...      \n",
       "7         JUNOIMZOOMIN               95.0        0.0           6.0    ...      \n",
       "8  FLIRT WITH THE BOYZ               97.0        0.0           6.0    ...      \n",
       "9   GEORGIES MAY KITTY               94.0        0.0           6.0    ...      \n",
       "\n",
       "   trainer_win_pct  imp_finish_pos  recent_race  was_claimed  was_favorite  \\\n",
       "0              0.0            True        False        False         False   \n",
       "1              0.0            True        False        False          True   \n",
       "2              0.0           False        False        False         False   \n",
       "3              0.0           False        False        False         False   \n",
       "4              0.0            True        False        False          True   \n",
       "5              0.0           False        False        False         False   \n",
       "6              0.0            True        False        False          True   \n",
       "7              0.0           False        False        False          True   \n",
       "8              0.0            True        False        False         False   \n",
       "9              0.0            True        False        False         False   \n",
       "\n",
       "   improved_stretch_pos  had_bullet  won_by_margin  won_at_similar_dist  \\\n",
       "0                 False       False           True                 True   \n",
       "1                 False       False           True                 True   \n",
       "2                 False       False           True                 True   \n",
       "3                 False       False           True                 True   \n",
       "4                  True       False           True                 True   \n",
       "5                 False       False           True                 True   \n",
       "6                 False        True           True                 True   \n",
       "7                 False       False           True                 True   \n",
       "8                 False       False           True                 True   \n",
       "9                  True       False           True                 True   \n",
       "\n",
       "      label  \n",
       "0  0.200000  \n",
       "1  0.800000  \n",
       "2  0.400000  \n",
       "3  1.000000  \n",
       "4  0.600000  \n",
       "5  0.833333  \n",
       "6  0.166667  \n",
       "7  0.666667  \n",
       "8  1.000000  \n",
       "9  0.500000  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_label(master_df):\n",
    "    master_df['label'] = master_df['finish_pos'] / master_df['num_entrants']\n",
    "    return master_df\n",
    "\n",
    "# Apply label\n",
    "master_df = add_label(master_df)\n",
    "\n",
    "# Drop all horses that did not finish (label == 0)\n",
    "dnf_index = master_df.loc[master_df['label'] == 0].index\n",
    "master_df = master_df.drop(dnf_index)\n",
    "master_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Columns Unused in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_pos</th>\n",
       "      <th>lt_earnings</th>\n",
       "      <th>app_weight_alw</th>\n",
       "      <th>ml_odds</th>\n",
       "      <th>last_speed_rating</th>\n",
       "      <th>speed_par</th>\n",
       "      <th>num_entrants</th>\n",
       "      <th>jockey_win_pct</th>\n",
       "      <th>trainer_win_pct</th>\n",
       "      <th>imp_finish_pos</th>\n",
       "      <th>recent_race</th>\n",
       "      <th>was_claimed</th>\n",
       "      <th>was_favorite</th>\n",
       "      <th>improved_stretch_pos</th>\n",
       "      <th>had_bullet</th>\n",
       "      <th>won_by_margin</th>\n",
       "      <th>won_at_similar_dist</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_pos  lt_earnings  app_weight_alw  ml_odds  last_speed_rating  \\\n",
       "0         1        31833             0.0      3.0               98.0   \n",
       "1         2        22706             0.0      1.6               96.0   \n",
       "2         3        37294             0.0      2.5               92.0   \n",
       "3         4        39885             0.0      4.5               94.0   \n",
       "4         5       134484             0.0      2.0               97.0   \n",
       "\n",
       "   speed_par  num_entrants  jockey_win_pct  trainer_win_pct  imp_finish_pos  \\\n",
       "0        0.0           5.0             0.0              0.0            True   \n",
       "1        0.0           5.0             0.0              0.0            True   \n",
       "2        0.0           5.0             0.0              0.0           False   \n",
       "3        0.0           5.0             0.0              0.0           False   \n",
       "4        0.0           5.0             0.0              0.0            True   \n",
       "\n",
       "   recent_race  was_claimed  was_favorite  improved_stretch_pos  had_bullet  \\\n",
       "0        False        False         False                 False       False   \n",
       "1        False        False          True                 False       False   \n",
       "2        False        False         False                 False       False   \n",
       "3        False        False         False                 False       False   \n",
       "4        False        False          True                  True       False   \n",
       "\n",
       "   won_by_margin  won_at_similar_dist  label  \n",
       "0           True                 True    0.2  \n",
       "1           True                 True    0.8  \n",
       "2           True                 True    0.4  \n",
       "3           True                 True    1.0  \n",
       "4           True                 True    0.6  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_cols = ['date', 'race_num', 'horse_name', 'finish_pos']\n",
    "master_df = master_df.drop(unused_cols, axis=1)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Boolean Columns to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_pos</th>\n",
       "      <th>lt_earnings</th>\n",
       "      <th>app_weight_alw</th>\n",
       "      <th>ml_odds</th>\n",
       "      <th>last_speed_rating</th>\n",
       "      <th>speed_par</th>\n",
       "      <th>num_entrants</th>\n",
       "      <th>jockey_win_pct</th>\n",
       "      <th>trainer_win_pct</th>\n",
       "      <th>imp_finish_pos</th>\n",
       "      <th>recent_race</th>\n",
       "      <th>was_claimed</th>\n",
       "      <th>was_favorite</th>\n",
       "      <th>improved_stretch_pos</th>\n",
       "      <th>had_bullet</th>\n",
       "      <th>won_by_margin</th>\n",
       "      <th>won_at_similar_dist</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_pos  lt_earnings  app_weight_alw  ml_odds  last_speed_rating  \\\n",
       "0         1        31833             0.0      3.0               98.0   \n",
       "1         2        22706             0.0      1.6               96.0   \n",
       "2         3        37294             0.0      2.5               92.0   \n",
       "3         4        39885             0.0      4.5               94.0   \n",
       "4         5       134484             0.0      2.0               97.0   \n",
       "\n",
       "   speed_par  num_entrants  jockey_win_pct  trainer_win_pct  imp_finish_pos  \\\n",
       "0        0.0           5.0             0.0              0.0               1   \n",
       "1        0.0           5.0             0.0              0.0               1   \n",
       "2        0.0           5.0             0.0              0.0               0   \n",
       "3        0.0           5.0             0.0              0.0               0   \n",
       "4        0.0           5.0             0.0              0.0               1   \n",
       "\n",
       "   recent_race  was_claimed  was_favorite  improved_stretch_pos  had_bullet  \\\n",
       "0            0            0             0                     0           0   \n",
       "1            0            0             1                     0           0   \n",
       "2            0            0             0                     0           0   \n",
       "3            0            0             0                     0           0   \n",
       "4            0            0             1                     1           0   \n",
       "\n",
       "   won_by_margin  won_at_similar_dist  label  \n",
       "0              1                    1    0.2  \n",
       "1              1                    1    0.8  \n",
       "2              1                    1    0.4  \n",
       "3              1                    1    1.0  \n",
       "4              1                    1    0.6  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_cols = ['imp_finish_pos', 'recent_race', 'was_claimed','was_favorite', \\\n",
    "             'improved_stretch_pos', 'had_bullet', 'won_by_margin', \\\n",
    "             'won_at_similar_dist']\n",
    "\n",
    "for col in bool_cols:\n",
    "    master_df[col] = master_df[col].apply(lambda x: int(x))\n",
    "\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader\n",
    "This will return the training data and the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle as df_shuffle\n",
    "\n",
    "def dataloader(df, shuffle=True):\n",
    "    if shuffle:\n",
    "            df = df_shuffle(df)\n",
    "    \n",
    "    # Get labels and data\n",
    "    labels = df['label']\n",
    "    data = df.drop(['label'], axis=1)\n",
    "            \n",
    "    # Turn data and label into tensor\n",
    "    for ii in range(len(data)):        \n",
    "        yield torch.tensor(data.iloc[ii]), torch.tensor(labels.iloc[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0000e+00, 1.3208e+05, 0.0000e+00, 2.0000e+01, 6.5000e+01, 8.7000e+01,\n",
      "        8.0000e+00, 5.2632e-02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "# Test dataloader\n",
    "sample_data, sample_label = next(iter(dataloader(master_df)))\n",
    "print(sample_data, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test/Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.8 # Proportion of training data to testing data\n",
    "train_end_idx = int(len(master_df) * 0.8)\n",
    "\n",
    "train_data = master_df.loc[:train_end_idx,:].copy()\n",
    "test_data = master_df.loc[train_end_idx:,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Test/Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_series(s):\n",
    "    return (s - s.mean()) / s.std()\n",
    "\n",
    "# Standardize training data\n",
    "for col in train_data.columns:\n",
    "    if col != 'label':\n",
    "        train_data.loc[:,col] = standardize_series(train_data[col])\n",
    "\n",
    "# Standardize testing data\n",
    "for col in test_data.columns:\n",
    "    if col != 'label':\n",
    "        test_data.loc[:, col] = standardize_series(test_data[col])\n",
    "    \n",
    "# Ensure standardization\n",
    "#print(train_data.mean(), train_data.std())\n",
    "#print(test_data.mean(), test_data.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=17, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3)\n",
      "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3)\n",
      "  (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_features = train_data.shape[1] - 1 # Don't count label column\n",
    "output_size = 1\n",
    "drop_prob = 0.3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob),\n",
    "    nn.Linear(256, output_size),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nate/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/nate/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Entries Processed: 50... Training Loss: 0.091198... Validation Loss: 0.074777...\n",
      "Epoch: 1/5... Entries Processed: 100... Training Loss: 0.077709... Validation Loss: 0.074777...\n",
      "Epoch: 1/5... Entries Processed: 150... Training Loss: 0.071854... Validation Loss: 0.074661...\n",
      "Epoch: 1/5... Entries Processed: 200... Training Loss: 0.071083... Validation Loss: 0.074585...\n",
      "Epoch: 1/5... Entries Processed: 250... Training Loss: 0.073658... Validation Loss: 0.074434...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-b9bb54e5c957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Validation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;31m# Set tensors to correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-b1d824c4bfb9>\u001b[0m in \u001b[0;36mdataloader\u001b[0;34m(df, shuffle)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Turn data and label into tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                     \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/julie-stav-ws/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \"\"\"\n\u001b[1;32m   3789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3790\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3792\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# Use GPU if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Training/Validation Loop\n",
    "epochs = 5\n",
    "lr = 0.00001\n",
    "print_every = 50\n",
    "clip = 5\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "training_losses = [x for x in range(epochs)]\n",
    "validation_losses = [x for x in range(epochs)]\n",
    "\n",
    "# Save metrics\n",
    "lowest_val_loss=100\n",
    "today = datetime.strftime(datetime.now(), '%Y%m%d')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting Epoch {}'.format(epoch+1))\n",
    "    entries_processed = 0\n",
    "    \n",
    "    # Begin Training Loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for data, label in dataloader(train_data):\n",
    "        entries_processed += 1\n",
    "        \n",
    "        # Set tensors to correct device\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform pass through network\n",
    "        train_out = model(data)\n",
    "        \n",
    "        # Calculate Loss and perform backprop -- clip gradients if necessary\n",
    "        train_loss = criterion(train_out, label)\n",
    "        train_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # Log Loss\n",
    "        train_losses.append(train_loss.item())\n",
    "    \n",
    "        # Take optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        if entries_processed % print_every == 0:\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            for data, label in dataloader(test_data):\n",
    "                # Set tensors to correct device\n",
    "                data, label = data.to(device), label.to(device)\n",
    "                \n",
    "                # Generate prediction\n",
    "                val_out = model(data)\n",
    "                \n",
    "                # Calculate and log loss\n",
    "                val_loss = criterion(val_out, label)\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            # Set back to training mode\n",
    "            model.train()\n",
    "                \n",
    "            # If this iteration has lowest validation loss, save model\n",
    "            if np.mean(val_losses) < lowest_val_loss:\n",
    "                torch.save(model, './models/linear-model-{}e-{}.pth'.format(epochs, today))\n",
    "                \n",
    "            # Print Metrics\n",
    "            print(\n",
    "                'Epoch: {}/{}...'.format(epoch+1, epochs),\n",
    "                'Entries Processed: {}...'.format(entries_processed),\n",
    "                'Training Loss: {:.6f}...'.format(np.mean(train_losses)),\n",
    "                'Validation Loss: {:.6f}...'.format(np.mean(val_losses))\n",
    "                 )\n",
    "            \n",
    "        # Log Epoch-level metrics\n",
    "        training_losses[epoch] = np.mean(train_losses)\n",
    "        validation_losses[epoch] = np.mean(val_losses)\n",
    "        \n",
    "# End Time\n",
    "end_time = time.time() - start_time\n",
    "print('Elapsed Time: {} Minutes'.format(end_time//60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training losses\n",
    "plt.title('Training Losses')\n",
    "plt.plot(training_losses[:4])\n",
    "plt.show()\n",
    "\n",
    "# Plot Validation Losses\n",
    "plt.title('Validation Losses')\n",
    "plt.plot(validation_losses[:4])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/linear-model-5e.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4724], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.09324448555707932\n",
      "tensor([0.6198], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.13673928380012512\n",
      "tensor([0.3597], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.061803147196769714\n",
      "tensor([0.6748], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.040061984211206436\n",
      "tensor([0.4975], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.13874535262584686\n",
      "tensor([0.7695], grad_fn=<SigmoidBackward>) tensor(1.) 0.0531235933303833\n",
      "tensor([0.4710], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.11974690854549408\n",
      "tensor([0.5150], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.04621150717139244\n",
      "tensor([0.7233], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.07773594558238983\n",
      "tensor([0.5410], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.01579822599887848\n",
      "tensor([0.4496], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.0940626934170723\n",
      "tensor([0.3485], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.02203790657222271\n",
      "tensor([0.3574], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.0033000397961586714\n",
      "tensor([0.3285], grad_fn=<SigmoidBackward>) tensor(0.2727) 0.0031098686158657074\n",
      "tensor([0.3828], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.06427936255931854\n",
      "tensor([0.6046], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.1917843520641327\n",
      "tensor([0.5240], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.0957074984908104\n",
      "tensor([0.5617], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.17546898126602173\n",
      "tensor([0.4076], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.034365877509117126\n",
      "tensor([0.3302], grad_fn=<SigmoidBackward>) tensor(0.4167) 0.0074767377227544785\n",
      "tensor([0.3888], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.00019162452372256666\n",
      "tensor([0.5481], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.005911639891564846\n",
      "tensor([0.3773], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.0019342248560860753\n",
      "tensor([0.6417], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.22561608254909515\n",
      "tensor([0.5116], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.02403920330107212\n",
      "tensor([0.4387], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.11498379707336426\n",
      "tensor([0.5446], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.044630832970142365\n",
      "tensor([0.5875], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.007650124374777079\n",
      "tensor([0.7232], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.00589120015501976\n",
      "tensor([0.4677], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.0716387927532196\n",
      "tensor([0.3826], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.046616487205028534\n",
      "tensor([0.5606], grad_fn=<SigmoidBackward>) tensor(1.) 0.19307835400104523\n",
      "tensor([0.9448], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.007677988614886999\n",
      "tensor([0.6622], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.018995240330696106\n",
      "tensor([0.4660], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.00436060968786478\n",
      "tensor([0.5101], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00010186089639319107\n",
      "tensor([0.5248], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.02013251557946205\n",
      "tensor([0.3962], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.012217563576996326\n",
      "tensor([0.5278], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.13040049374103546\n",
      "tensor([0.5231], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.000531368947122246\n",
      "tensor([0.7281], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.011076245456933975\n",
      "tensor([0.5230], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.10435215383768082\n",
      "tensor([0.6885], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.2722751498222351\n",
      "tensor([0.5820], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.006725909188389778\n",
      "tensor([0.3774], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0026232777163386345\n",
      "tensor([0.5880], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.025413230061531067\n",
      "tensor([0.4525], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.09585466980934143\n",
      "tensor([0.5413], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.015705181285738945\n",
      "tensor([0.4800], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.07290603965520859\n",
      "tensor([0.6082], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.12828846275806427\n",
      "tensor([0.5212], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.0025250439066439867\n",
      "tensor([0.3955], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.07314961403608322\n",
      "tensor([0.4622], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.08280225843191147\n",
      "tensor([0.4317], grad_fn=<SigmoidBackward>) tensor(0.5833) 0.022999867796897888\n",
      "tensor([0.5719], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.02027248777449131\n",
      "tensor([0.4545], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.01468209270387888\n",
      "tensor([0.5491], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.09491913765668869\n",
      "tensor([0.4735], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.12143121659755707\n",
      "tensor([0.5124], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.018892038613557816\n",
      "tensor([0.5152], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.01965552754700184\n",
      "tensor([0.3638], grad_fn=<SigmoidBackward>) tensor(0.3636) 1.5630185146164877e-08\n",
      "tensor([0.4919], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.1218390166759491\n",
      "tensor([0.3884], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.012446315959095955\n",
      "tensor([0.5591], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.050969790667295456\n",
      "tensor([0.6048], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.19196867942810059\n",
      "tensor([0.5712], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.005067404825240374\n",
      "tensor([0.3749], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.07558885216712952\n",
      "tensor([0.5197], grad_fn=<SigmoidBackward>) tensor(1.) 0.2306603342294693\n",
      "tensor([0.3704], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.030645765364170074\n",
      "tensor([0.4542], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.05379210785031319\n",
      "tensor([0.6570], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.047522127628326416\n",
      "tensor([0.6439], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.020710600540041924\n",
      "tensor([0.4377], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.03506956622004509\n",
      "tensor([0.4963], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.026558173820376396\n",
      "tensor([0.4040], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.04883613437414169\n",
      "tensor([0.4712], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.09273011237382889\n",
      "tensor([0.7106], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.019377926364541054\n",
      "tensor([0.5064], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.12298904359340668\n",
      "tensor([0.2437], grad_fn=<SigmoidBackward>) tensor(0.3846) 0.019865762442350388\n",
      "tensor([0.4464], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.0050918105989694595\n",
      "tensor([0.4184], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.0018804018618538976\n",
      "tensor([0.4361], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.09675723314285278\n",
      "tensor([0.3668], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.06664810329675674\n",
      "tensor([0.5033], grad_fn=<SigmoidBackward>) tensor(1.) 0.24673248827457428\n",
      "tensor([0.5596], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.011473732069134712\n",
      "tensor([0.4405], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.011494305916130543\n",
      "tensor([0.4174], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.043077751994132996\n",
      "tensor([0.4649], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.08015062659978867\n",
      "tensor([0.4611], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.06408154964447021\n",
      "tensor([0.5157], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0002467908780090511\n",
      "tensor([0.4435], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.016353128477931023\n",
      "tensor([0.5152], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.1386057585477829\n",
      "tensor([0.4802], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.02157992497086525\n",
      "tensor([0.4187], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.06147712841629982\n",
      "tensor([0.6068], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.011556625366210938\n",
      "tensor([0.6321], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.005854730494320393\n",
      "tensor([0.5330], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.09655964374542236\n",
      "tensor([0.5691], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.08299700915813446\n",
      "tensor([0.4710], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.11969291418790817\n",
      "tensor([0.5216], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00046771462075412273\n",
      "tensor([0.5208], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.05524706840515137\n",
      "tensor([0.4208], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.06044667586684227\n",
      "tensor([0.4405], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.04762592911720276\n",
      "tensor([0.5439], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.16086073219776154\n",
      "tensor([0.7018], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.00015688662824686617\n",
      "tensor([0.6789], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.0012495736591517925\n",
      "tensor([0.3530], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.05197044461965561\n",
      "tensor([0.4775], grad_fn=<SigmoidBackward>) tensor(0.2727) 0.04193086177110672\n",
      "tensor([0.5199], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.021526126191020012\n",
      "tensor([0.4212], grad_fn=<SigmoidBackward>) tensor(0.4286) 5.4786116379546e-05\n",
      "tensor([0.6498], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.010036683641374111\n",
      "tensor([0.3967], grad_fn=<SigmoidBackward>) tensor(0.4545) 0.00334146642126143\n",
      "tensor([0.4580], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.0068899355828762054\n",
      "tensor([0.5989], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.010225108824670315\n",
      "tensor([0.5571], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.05005500465631485\n",
      "tensor([0.6195], grad_fn=<SigmoidBackward>) tensor(0.8182) 0.0394563302397728\n",
      "tensor([0.5122], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.04083960875868797\n",
      "tensor([0.4536], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.0679817646741867\n",
      "tensor([0.4541], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.029193289577960968\n",
      "tensor([0.5151], grad_fn=<SigmoidBackward>) tensor(0.3571) 0.024940289556980133\n",
      "tensor([0.3345], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.027390817180275917\n",
      "tensor([0.4117], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.00013701287389267236\n",
      "tensor([0.5950], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.03339376673102379\n",
      "tensor([0.7105], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.0045323739759624004\n",
      "tensor([0.5676], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.0010509159183129668\n",
      "tensor([0.4452], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.012516255490481853\n",
      "tensor([0.4089], grad_fn=<SigmoidBackward>) tensor(1.) 0.34944358468055725\n",
      "tensor([0.5208], grad_fn=<SigmoidBackward>) tensor(0.4545) 0.004385445732623339\n",
      "tensor([0.7084], grad_fn=<SigmoidBackward>) tensor(0.7143) 3.4791311918525025e-05\n",
      "tensor([0.5441], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.10951237380504608\n",
      "tensor([0.5456], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.08738231658935547\n",
      "tensor([0.3675], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.06571034342050552\n",
      "tensor([0.6400], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.012098652310669422\n",
      "tensor([0.4721], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.009865041822195053\n",
      "tensor([0.5002], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.11097567528486252\n",
      "tensor([0.4944], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.13155212998390198\n",
      "tensor([0.3745], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.06274154037237167\n",
      "tensor([0.3171], grad_fn=<SigmoidBackward>) tensor(0.3846) 0.0045555210672318935\n",
      "tensor([0.4327], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.033386796712875366\n",
      "tensor([0.6257], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.03038462996482849\n",
      "tensor([0.5148], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.019531579688191414\n",
      "tensor([0.4972], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.1295851469039917\n",
      "tensor([0.3176], grad_fn=<SigmoidBackward>) tensor(0.3571) 0.0015609421534463763\n",
      "tensor([0.5070], grad_fn=<SigmoidBackward>) tensor(0.5000) 4.923517190036364e-05\n",
      "tensor([0.2691], grad_fn=<SigmoidBackward>) tensor(0.6429) 0.13967373967170715\n",
      "tensor([0.4620], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.011970695108175278\n",
      "tensor([0.2808], grad_fn=<SigmoidBackward>) tensor(0.3846) 0.01077370997518301\n",
      "tensor([0.6534], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.16274411976337433\n",
      "tensor([0.4642], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.11507470905780792\n",
      "tensor([0.5162], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.0015455415705218911\n",
      "tensor([0.4414], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.02516668662428856\n",
      "tensor([0.5355], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.017199058085680008\n",
      "tensor([0.5512], grad_fn=<SigmoidBackward>) tensor(1.) 0.2013777494430542\n",
      "tensor([0.4212], grad_fn=<SigmoidBackward>) tensor(0.2143) 0.04282943531870842\n",
      "tensor([0.4605], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.07763762772083282\n",
      "tensor([0.5793], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.00042816094355657697\n",
      "tensor([0.7275], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.05176564306020737\n",
      "tensor([0.5744], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.030849404633045197\n",
      "tensor([0.5350], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.01133212074637413\n",
      "tensor([0.5320], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.06067861244082451\n",
      "tensor([0.5453], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.06737644970417023\n",
      "tensor([0.4554], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.054394543170928955\n",
      "tensor([0.5401], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0016094378661364317\n",
      "tensor([0.6279], grad_fn=<SigmoidBackward>) tensor(0.6250) 8.618729225418065e-06\n",
      "tensor([0.5771], grad_fn=<SigmoidBackward>) tensor(1.) 0.1788834035396576\n",
      "tensor([0.5654], grad_fn=<SigmoidBackward>) tensor(0.5714) 3.642950105131604e-05\n",
      "tensor([0.5287], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.05905238911509514\n",
      "tensor([0.5542], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.005013712681829929\n",
      "tensor([0.5118], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00013973537716083229\n",
      "tensor([0.5366], grad_fn=<SigmoidBackward>) tensor(0.4545) 0.006728642154484987\n",
      "tensor([0.3876], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.012641927227377892\n",
      "tensor([0.3947], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.058388132601976395\n",
      "tensor([0.4269], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.04187683016061783\n",
      "tensor([0.2093], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.4431192874908447\n",
      "tensor([0.6219], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.2609492838382721\n",
      "tensor([0.4395], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.09893330931663513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7023], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.017135659232735634\n",
      "tensor([0.4878], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.040840763598680496\n",
      "tensor([0.4604], grad_fn=<SigmoidBackward>) tensor(1.) 0.2911338806152344\n",
      "tensor([0.5445], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.013429662212729454\n",
      "tensor([0.4090], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.07084648311138153\n",
      "tensor([0.6239], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.06195376068353653\n",
      "tensor([0.4868], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.03236624598503113\n",
      "tensor([0.4696], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.17577634751796722\n",
      "tensor([0.3156], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.034002721309661865\n",
      "tensor([0.4768], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.07463297992944717\n",
      "tensor([0.5860], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.11290214210748672\n",
      "tensor([0.4449], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.09120366722345352\n",
      "tensor([0.4758], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.036434173583984375\n",
      "tensor([0.5292], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.03835016489028931\n",
      "tensor([0.4513], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.014427874237298965\n",
      "tensor([0.3343], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.01804501935839653\n",
      "tensor([0.5430], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.04398094862699509\n",
      "tensor([0.5333], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.061312779784202576\n",
      "tensor([0.5099], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.04176812991499901\n",
      "tensor([0.4311], grad_fn=<SigmoidBackward>) tensor(0.4286) 6.406825832527829e-06\n",
      "tensor([0.4466], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.038670238107442856\n",
      "tensor([0.4467], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.03869684785604477\n",
      "tensor([0.4971], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.005519147031009197\n",
      "tensor([0.5629], grad_fn=<SigmoidBackward>) tensor(1.) 0.19109173119068146\n",
      "tensor([0.4073], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.008594131097197533\n",
      "tensor([0.5720], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.008963502943515778\n",
      "tensor([0.5043], grad_fn=<SigmoidBackward>) tensor(0.5000) 1.8272263332619332e-05\n",
      "tensor([0.6941], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.03768661990761757\n",
      "tensor([0.4285], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.08161339908838272\n",
      "tensor([0.6313], grad_fn=<SigmoidBackward>) tensor(0.6250) 3.997630483354442e-05\n",
      "tensor([0.4978], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.04686824232339859\n",
      "tensor([0.5196], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.0026862802915275097\n",
      "tensor([0.6050], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.00039943677256815135\n",
      "tensor([0.6652], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.04401179030537605\n",
      "tensor([0.6172], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.009422488510608673\n",
      "tensor([0.5054], grad_fn=<SigmoidBackward>) tensor(1.) 0.24458499252796173\n",
      "tensor([0.5851], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.016691941767930984\n",
      "tensor([0.4010], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.040407802909612656\n",
      "tensor([0.6500], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.02251109853386879\n",
      "tensor([0.5369], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.01682918891310692\n",
      "tensor([0.5123], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.09751544892787933\n",
      "tensor([0.4892], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.02428353577852249\n",
      "tensor([0.5087], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.030740676447749138\n",
      "tensor([0.4972], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.06390254199504852\n",
      "tensor([0.4212], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.07749438285827637\n",
      "tensor([0.5296], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.03411521762609482\n",
      "tensor([0.6650], grad_fn=<SigmoidBackward>) tensor(0.6667) 2.763684051387827e-06\n",
      "tensor([0.6585], grad_fn=<SigmoidBackward>) tensor(1.) 0.11662928014993668\n",
      "tensor([0.5262], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.03537532314658165\n",
      "tensor([0.5001], grad_fn=<SigmoidBackward>) tensor(0.5000) 3.703494400042473e-09\n",
      "tensor([0.4446], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.003066140925511718\n",
      "tensor([0.4410], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.07466625422239304\n",
      "tensor([0.4683], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.00871214084327221\n",
      "tensor([0.4933], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.1457126885652542\n",
      "tensor([0.4429], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.020415067672729492\n",
      "tensor([0.4276], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.0810854360461235\n",
      "tensor([0.6598], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.16793574392795563\n",
      "tensor([0.4405], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.05115737393498421\n",
      "tensor([0.5317], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.0001894696761155501\n",
      "tensor([0.4677], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0015314440242946148\n",
      "tensor([0.5168], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00028286874294281006\n",
      "tensor([0.5107], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.003691504942253232\n",
      "tensor([0.7271], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.22759149968624115\n",
      "tensor([0.4400], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.08831024914979935\n",
      "tensor([0.6191], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.06548107415437698\n",
      "tensor([0.5337], grad_fn=<SigmoidBackward>) tensor(1.) 0.2174072414636612\n",
      "tensor([0.6857], grad_fn=<SigmoidBackward>) tensor(1.) 0.09881094098091125\n",
      "tensor([0.7596], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.22460390627384186\n",
      "tensor([0.5056], grad_fn=<SigmoidBackward>) tensor(1.) 0.24439696967601776\n",
      "tensor([0.5256], grad_fn=<SigmoidBackward>) tensor(0.3636) 0.02624560333788395\n",
      "tensor([0.5455], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.06474629789590836\n",
      "tensor([0.6777], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.06206761673092842\n",
      "tensor([0.5967], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.03869042545557022\n",
      "tensor([0.4207], grad_fn=<SigmoidBackward>) tensor(0.2727) 0.021894024685025215\n",
      "tensor([0.6113], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.01061544381082058\n",
      "tensor([0.5448], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.042097799479961395\n",
      "tensor([0.6775], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.04468090087175369\n",
      "tensor([0.3848], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.08108998835086823\n",
      "tensor([0.6220], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.016371816396713257\n",
      "tensor([0.4947], grad_fn=<SigmoidBackward>) tensor(0.5000) 2.8326954634394497e-05\n",
      "tensor([0.2991], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.0011689438251778483\n",
      "tensor([0.6448], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.07281356304883957\n",
      "tensor([0.4960], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.029124710708856583\n",
      "tensor([0.4938], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.0656433030962944\n",
      "tensor([0.5314], grad_fn=<SigmoidBackward>) tensor(0.5833) 0.0027007884345948696\n",
      "tensor([0.5629], grad_fn=<SigmoidBackward>) tensor(0.8182) 0.06516575813293457\n",
      "tensor([0.4132], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.04546985402703285\n",
      "tensor([0.4632], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.000350527698174119\n",
      "tensor([0.5219], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.031727761030197144\n",
      "tensor([0.7177], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.0010433821007609367\n",
      "tensor([0.4395], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.09642244130373001\n",
      "tensor([0.4826], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.08711434155702591\n",
      "tensor([0.3918], grad_fn=<SigmoidBackward>) tensor(0.4167) 0.000619861064478755\n",
      "tensor([0.7032], grad_fn=<SigmoidBackward>) tensor(0.9000) 0.038722191005945206\n",
      "tensor([0.3191], grad_fn=<SigmoidBackward>) tensor(0.8182) 0.2491152137517929\n",
      "tensor([0.6938], grad_fn=<SigmoidBackward>) tensor(1.) 0.09373334795236588\n",
      "tensor([0.5935], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.05751434713602066\n",
      "tensor([0.6315], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.25650638341903687\n",
      "tensor([0.4818], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.05370821803808212\n",
      "tensor([0.3623], grad_fn=<SigmoidBackward>) tensor(0.4167) 0.0029525835998356342\n",
      "tensor([0.4348], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.1047622337937355\n",
      "tensor([0.5298], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.07827896624803543\n",
      "tensor([0.7467], grad_fn=<SigmoidBackward>) tensor(1.) 0.06418103724718094\n",
      "tensor([0.4455], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.0382382869720459\n",
      "tensor([0.5454], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.028533577919006348\n",
      "tensor([0.5875], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.026418346911668777\n",
      "tensor([0.3939], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.008825097233057022\n",
      "tensor([0.5697], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.019906019791960716\n",
      "tensor([0.4453], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.11170738935470581\n",
      "tensor([0.5062], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.14534789323806763\n",
      "tensor([0.4464], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.11241065710783005\n",
      "tensor([0.3642], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.07889833301305771\n",
      "tensor([0.4249], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.044731464236974716\n",
      "tensor([0.4294], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.009231241419911385\n",
      "tensor([0.7226], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.049572303891181946\n",
      "tensor([0.6591], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.13939274847507477\n",
      "tensor([0.7908], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.036386653780937195\n",
      "tensor([0.4457], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.002949193585664034\n",
      "tensor([0.4762], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.17032203078269958\n",
      "tensor([0.6226], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.024076422676444054\n",
      "tensor([0.6466], grad_fn=<SigmoidBackward>) tensor(0.9091) 0.06889764219522476\n",
      "tensor([0.4718], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.10817570984363556\n",
      "tensor([0.5498], grad_fn=<SigmoidBackward>) tensor(1.) 0.20268231630325317\n",
      "tensor([0.4068], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.03407145291566849\n",
      "tensor([0.4540], grad_fn=<SigmoidBackward>) tensor(0.7273) 0.07468578219413757\n",
      "tensor([0.4907], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.036369748413562775\n",
      "tensor([0.5325], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.04730955511331558\n",
      "tensor([0.4345], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.03628002852201462\n",
      "tensor([0.5990], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.010208889842033386\n",
      "tensor([0.4420], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0033658496104180813\n",
      "tensor([0.5241], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.000986803905107081\n",
      "tensor([0.6660], grad_fn=<SigmoidBackward>) tensor(1.) 0.11154564470052719\n",
      "tensor([0.7528], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.01851949281990528\n",
      "tensor([0.5874], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.04518568143248558\n",
      "tensor([0.6387], grad_fn=<SigmoidBackward>) tensor(1.) 0.1305612474679947\n",
      "tensor([0.6421], grad_fn=<SigmoidBackward>) tensor(1.) 0.1281096190214157\n",
      "tensor([0.6495], grad_fn=<SigmoidBackward>) tensor(1.) 0.12286753952503204\n",
      "tensor([0.5361], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.05840764939785004\n",
      "tensor([0.6348], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.09087924659252167\n",
      "tensor([0.4099], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.07130212336778641\n",
      "tensor([0.5444], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.08664906024932861\n",
      "tensor([0.5156], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.12174619734287262\n",
      "tensor([0.5478], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.1639716774225235\n",
      "tensor([0.4770], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.10430523008108139\n",
      "tensor([0.5998], grad_fn=<SigmoidBackward>) tensor(1.) 0.16016462445259094\n",
      "tensor([0.5635], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.0053102909587323666\n",
      "tensor([0.3673], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.08065734058618546\n",
      "tensor([0.4569], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.14171086251735687\n",
      "tensor([0.3788], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.03196006268262863\n",
      "tensor([0.5529], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.03884873166680336\n",
      "tensor([0.4383], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.08726927638053894\n",
      "tensor([0.5129], grad_fn=<SigmoidBackward>) tensor(0.6429) 0.016891909763216972\n",
      "tensor([0.3842], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.04732504487037659\n",
      "tensor([0.6083], grad_fn=<SigmoidBackward>) tensor(0.3636) 0.05985942855477333\n",
      "tensor([0.4073], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.014791279099881649\n",
      "tensor([0.3485], grad_fn=<SigmoidBackward>) tensor(0.9000) 0.3041194677352905\n",
      "tensor([0.2941], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.0444134958088398\n",
      "tensor([0.4553], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.11843650043010712\n",
      "tensor([0.4301], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.1017676368355751\n",
      "tensor([0.3997], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.004404847510159016\n",
      "tensor([0.6848], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.022064048796892166\n",
      "tensor([0.7543], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.3072844445705414\n",
      "tensor([0.3238], grad_fn=<SigmoidBackward>) tensor(0.4167) 0.008630139753222466\n",
      "tensor([0.3143], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.004136057570576668\n",
      "tensor([0.5542], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.01205231249332428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6213], grad_fn=<SigmoidBackward>) tensor(1.) 0.1434154212474823\n",
      "tensor([0.4200], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.0180253554135561\n",
      "tensor([0.6180], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.002372819697484374\n",
      "tensor([0.8373], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.0014211010420694947\n",
      "tensor([0.3535], grad_fn=<SigmoidBackward>) tensor(0.2727) 0.006517740432173014\n",
      "tensor([0.3977], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.009544812142848969\n",
      "tensor([0.7710], grad_fn=<SigmoidBackward>) tensor(1.) 0.05243790149688721\n",
      "tensor([0.7479], grad_fn=<SigmoidBackward>) tensor(0.7500) 4.241619535605423e-06\n",
      "tensor([0.3912], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.019942238926887512\n",
      "tensor([0.5062], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.042519424110651016\n",
      "tensor([0.5228], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.11176799237728119\n",
      "tensor([0.5465], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.0454438216984272\n",
      "tensor([0.3939], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.011263957247138023\n",
      "tensor([0.4437], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.010360429994761944\n",
      "tensor([0.7619], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.06859392672777176\n",
      "tensor([0.4238], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.03021743893623352\n",
      "tensor([0.6903], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.09939051419496536\n",
      "tensor([0.3108], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.016645554453134537\n",
      "tensor([0.4048], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.05670449882745743\n",
      "tensor([0.3185], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.05528958514332771\n",
      "tensor([0.6006], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.08311237394809723\n",
      "tensor([0.5674], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.10077256709337234\n",
      "tensor([0.6096], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.16774116456508636\n",
      "tensor([0.5373], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.041604507714509964\n",
      "tensor([0.3498], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.056966934353113174\n",
      "tensor([0.7790], grad_fn=<SigmoidBackward>) tensor(0.7273) 0.002675386145710945\n",
      "tensor([0.4727], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.13007307052612305\n",
      "tensor([0.3386], grad_fn=<SigmoidBackward>) tensor(0.3636) 0.000625144864898175\n",
      "tensor([0.3362], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.004066502209752798\n",
      "tensor([0.2730], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.003645357210189104\n",
      "tensor([0.5375], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.11391782015562057\n",
      "tensor([0.5356], grad_fn=<SigmoidBackward>) tensor(1.) 0.2156655341386795\n",
      "tensor([0.5981], grad_fn=<SigmoidBackward>) tensor(0.6000) 3.5433329230727395e-06\n",
      "tensor([0.5232], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.020574351772665977\n",
      "tensor([0.6251], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.0017282587941735983\n",
      "tensor([0.6307], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.04106030985713005\n",
      "tensor([0.5797], grad_fn=<SigmoidBackward>) tensor(0.5833) 1.3285611203173175e-05\n",
      "tensor([0.6254], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.29383015632629395\n",
      "tensor([0.5131], grad_fn=<SigmoidBackward>) tensor(1.) 0.23709659278392792\n",
      "tensor([0.6539], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.0008373834425583482\n",
      "tensor([0.6199], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.059957556426525116\n",
      "tensor([0.5482], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.06338997185230255\n",
      "tensor([0.3683], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.27106061577796936\n",
      "tensor([0.5051], grad_fn=<SigmoidBackward>) tensor(0.5000) 2.6414152671350166e-05\n",
      "tensor([0.4902], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.11774244904518127\n",
      "tensor([0.5514], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.1669379621744156\n",
      "tensor([0.5932], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.06750758737325668\n",
      "tensor([0.4152], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.09936263412237167\n",
      "tensor([0.6908], grad_fn=<SigmoidBackward>) tensor(0.7000) 8.500737749272957e-05\n",
      "tensor([0.4256], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.10601036995649338\n",
      "tensor([0.3587], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.02519119717180729\n",
      "tensor([0.3928], grad_fn=<SigmoidBackward>) tensor(0.4000) 5.147547199157998e-05\n",
      "tensor([0.6564], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.00010611907055135816\n",
      "tensor([0.4353], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.014456246048212051\n",
      "tensor([0.5831], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.023892147466540337\n",
      "tensor([0.4213], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.04895748943090439\n",
      "tensor([0.7941], grad_fn=<SigmoidBackward>) tensor(0.8000) 3.461153755779378e-05\n",
      "tensor([0.3808], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.07884689420461655\n",
      "tensor([0.5143], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00020391559519339353\n",
      "tensor([0.4593], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0016570106381550431\n",
      "tensor([0.3380], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.05666397884488106\n",
      "tensor([0.4286], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.016537131741642952\n",
      "tensor([0.3864], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.045631930232048035\n",
      "tensor([0.3539], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0213461983948946\n",
      "tensor([0.7625], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.06889435648918152\n",
      "tensor([0.4079], grad_fn=<SigmoidBackward>) tensor(0.4000) 6.176046736072749e-05\n",
      "tensor([0.5420], grad_fn=<SigmoidBackward>) tensor(1.) 0.20980872213840485\n",
      "tensor([0.4990], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.07662070542573929\n",
      "tensor([0.3960], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.08758646994829178\n",
      "tensor([0.6800], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.0030266926623880863\n",
      "tensor([0.5618], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.035416971892118454\n",
      "tensor([0.4027], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.023328270763158798\n",
      "tensor([0.5269], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.009621424600481987\n",
      "tensor([0.4657], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.032388683408498764\n",
      "tensor([0.5300], grad_fn=<SigmoidBackward>) tensor(1.) 0.22094647586345673\n",
      "tensor([0.6063], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.07219309359788895\n",
      "tensor([0.4259], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.0396404005587101\n",
      "tensor([0.6263], grad_fn=<SigmoidBackward>) tensor(1.) 0.13965246081352234\n",
      "tensor([0.6175], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.07363627105951309\n",
      "tensor([0.3700], grad_fn=<SigmoidBackward>) tensor(0.3750) 2.512468199711293e-05\n",
      "tensor([0.6079], grad_fn=<SigmoidBackward>) tensor(0.6000) 6.262301030801609e-05\n",
      "tensor([0.3874], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0016992022283375263\n",
      "tensor([0.6576], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.053497400134801865\n",
      "tensor([0.7184], grad_fn=<SigmoidBackward>) tensor(1.) 0.07929973304271698\n",
      "tensor([0.4921], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.06652301549911499\n",
      "tensor([0.6878], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.1617005616426468\n",
      "tensor([0.6263], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.06895779073238373\n",
      "tensor([0.5259], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0006682378007099032\n",
      "tensor([0.4438], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.003161270869895816\n",
      "tensor([0.4535], grad_fn=<SigmoidBackward>) tensor(1.) 0.2986503541469574\n",
      "tensor([0.4037], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.023626958951354027\n",
      "tensor([0.6090], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.061575666069984436\n",
      "tensor([0.4419], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.020125284790992737\n",
      "tensor([0.5305], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.008935614489018917\n",
      "tensor([0.5277], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.034825243055820465\n",
      "tensor([0.2979], grad_fn=<SigmoidBackward>) tensor(0.6875) 0.15182587504386902\n",
      "tensor([0.3557], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.07250908017158508\n",
      "tensor([0.3774], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.13880062103271484\n",
      "tensor([0.2367], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.00017700818716548383\n",
      "tensor([0.3489], grad_fn=<SigmoidBackward>) tensor(0.1875) 0.026037221774458885\n",
      "tensor([0.4941], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.014173632487654686\n",
      "tensor([0.4217], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.04132823646068573\n",
      "tensor([0.4768], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.004714857321232557\n",
      "tensor([0.5969], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.004867001436650753\n",
      "tensor([0.4258], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.01583358459174633\n",
      "tensor([0.3684], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.07205837219953537\n",
      "tensor([0.3874], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.012689278461039066\n",
      "tensor([0.6306], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.001303672674112022\n",
      "tensor([0.3399], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.057574402540922165\n",
      "tensor([0.6385], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.19230100512504578\n",
      "tensor([0.4925], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.030317777767777443\n",
      "tensor([0.5208], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.10294324159622192\n",
      "tensor([0.6044], grad_fn=<SigmoidBackward>) tensor(1.) 0.15651677548885345\n",
      "tensor([0.3829], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.013723726384341717\n",
      "tensor([0.3742], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.03701554983854294\n",
      "tensor([0.4867], grad_fn=<SigmoidBackward>) tensor(1.) 0.26350998878479004\n",
      "tensor([0.5673], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.03336462751030922\n",
      "tensor([0.5813], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.17191244661808014\n",
      "tensor([0.5883], grad_fn=<SigmoidBackward>) tensor(0.8182) 0.05286012217402458\n",
      "tensor([0.2982], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.0001554289774503559\n",
      "tensor([0.5671], grad_fn=<SigmoidBackward>) tensor(0.6875) 0.014494583941996098\n",
      "tensor([0.8656], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.0010398156009614468\n",
      "tensor([0.6045], grad_fn=<SigmoidBackward>) tensor(0.7333) 0.01659044623374939\n",
      "tensor([0.5495], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.00048044571303762496\n",
      "tensor([0.4378], grad_fn=<SigmoidBackward>) tensor(0.6429) 0.042028095573186874\n",
      "tensor([0.5268], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0007162848487496376\n",
      "tensor([0.4584], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.08509185165166855\n",
      "tensor([0.3324], grad_fn=<SigmoidBackward>) tensor(0.7692) 0.19081291556358337\n",
      "tensor([0.4619], grad_fn=<SigmoidBackward>) tensor(0.5833) 0.014751776121556759\n",
      "tensor([0.6761], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.04529973119497299\n",
      "tensor([0.5917], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.025068793445825577\n",
      "tensor([0.3063], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.015502767637372017\n",
      "tensor([0.3315], grad_fn=<SigmoidBackward>) tensor(0.3571) 0.0006555378204211593\n",
      "tensor([0.3004], grad_fn=<SigmoidBackward>) tensor(0.4615) 0.025964312255382538\n",
      "tensor([0.6008], grad_fn=<SigmoidBackward>) tensor(1.) 0.15932244062423706\n",
      "tensor([0.4121], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.1980775147676468\n",
      "tensor([0.3466], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.027148330584168434\n",
      "tensor([0.4852], grad_fn=<SigmoidBackward>) tensor(1.) 0.26497727632522583\n",
      "tensor([0.5657], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00431468803435564\n",
      "tensor([0.6398], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.04724172502756119\n",
      "tensor([0.5432], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.0001536720956210047\n",
      "tensor([0.5021], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.102576345205307\n",
      "tensor([0.4333], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.054456550627946854\n",
      "tensor([0.4587], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0017040434759110212\n",
      "tensor([0.2645], grad_fn=<SigmoidBackward>) tensor(0.3571) 0.00859025213867426\n",
      "tensor([0.4173], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.028001651167869568\n",
      "tensor([0.4457], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.07786507159471512\n",
      "tensor([0.4104], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.0012562850024551153\n",
      "tensor([0.2948], grad_fn=<SigmoidBackward>) tensor(0.3636) 0.004732816945761442\n",
      "tensor([0.5270], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.1210743710398674\n",
      "tensor([0.6242], grad_fn=<SigmoidBackward>) tensor(0.6154) 7.736396219115704e-05\n",
      "tensor([0.4518], grad_fn=<SigmoidBackward>) tensor(1.) 0.30052539706230164\n",
      "tensor([0.4974], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.06382381170988083\n",
      "tensor([0.5368], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.011721145361661911\n",
      "tensor([0.5557], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.004808017984032631\n",
      "tensor([0.4781], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.006003374699503183\n",
      "tensor([0.4418], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.1282842606306076\n",
      "tensor([0.5972], grad_fn=<SigmoidBackward>) tensor(1.) 0.1622334122657776\n",
      "tensor([0.3971], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.004068608395755291\n",
      "tensor([0.2599], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.0221354141831398\n",
      "tensor([0.6577], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.0010693290969356894\n",
      "tensor([0.5088], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.030796799808740616\n",
      "tensor([0.3954], grad_fn=<SigmoidBackward>) tensor(0.4615) 0.0043792626820504665\n",
      "tensor([0.4922], grad_fn=<SigmoidBackward>) tensor(0.5000) 6.026367918821052e-05\n",
      "tensor([0.4004], grad_fn=<SigmoidBackward>) tensor(0.3077) 0.008596904575824738\n",
      "tensor([0.5253], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.01999778114259243\n",
      "tensor([0.3187], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.00021541310707107186\n",
      "tensor([0.4351], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.20590297877788544\n",
      "tensor([0.4590], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.11157859116792679\n",
      "tensor([0.2996], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.016624920070171356\n",
      "tensor([0.5403], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.0035612951032817364\n",
      "tensor([0.4127], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.0014211077941581607\n",
      "tensor([0.3766], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.0058720787055790424\n",
      "tensor([0.5596], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.1888909935951233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3329], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.04918595775961876\n",
      "tensor([0.3851], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.09918303787708282\n",
      "tensor([0.3597], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.007187119219452143\n",
      "tensor([0.4836], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00026834383606910706\n",
      "tensor([0.5024], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.06130275875329971\n",
      "tensor([0.7544], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.2832172214984894\n",
      "tensor([0.4451], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.015963226556777954\n",
      "tensor([0.4974], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.12571334838867188\n",
      "tensor([0.4413], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.000162532101967372\n",
      "tensor([0.4408], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.1733763962984085\n",
      "tensor([0.7176], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.10089246928691864\n",
      "tensor([0.6299], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.02893608994781971\n",
      "tensor([0.4478], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.026279140263795853\n",
      "tensor([0.6044], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.07321520894765854\n",
      "tensor([0.4729], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.037561073899269104\n",
      "tensor([0.4814], grad_fn=<SigmoidBackward>) tensor(1.) 0.26895782351493835\n",
      "tensor([0.5471], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.014306355267763138\n",
      "tensor([0.6448], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.0030424860306084156\n",
      "tensor([0.3230], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.14216187596321106\n",
      "tensor([0.6318], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.02829800359904766\n",
      "tensor([0.3472], grad_fn=<SigmoidBackward>) tensor(0.4545) 0.011517501436173916\n",
      "tensor([0.3426], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.020326290279626846\n",
      "tensor([0.2322], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.004294386133551598\n",
      "tensor([0.4257], grad_fn=<SigmoidBackward>) tensor(0.4545) 0.0008346380782313645\n",
      "tensor([0.4390], grad_fn=<SigmoidBackward>) tensor(0.7273) 0.08309739083051682\n",
      "tensor([0.5403], grad_fn=<SigmoidBackward>) tensor(0.4167) 0.015292915515601635\n",
      "tensor([0.6535], grad_fn=<SigmoidBackward>) tensor(1.) 0.12008830159902573\n",
      "tensor([0.4843], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.11658266931772232\n",
      "tensor([0.4531], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.021571466699242592\n",
      "tensor([0.5749], grad_fn=<SigmoidBackward>) tensor(0.9000) 0.10567861795425415\n",
      "tensor([0.6997], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.17138579487800598\n",
      "tensor([0.5606], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.17453399300575256\n",
      "tensor([0.5743], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.008532729931175709\n",
      "tensor([0.5241], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.1453832983970642\n",
      "tensor([0.6553], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.13662488758563995\n",
      "tensor([0.4677], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.0005415697232820094\n",
      "tensor([0.4554], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.11855574697256088\n",
      "tensor([0.5387], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.042181383818387985\n",
      "tensor([0.5735], grad_fn=<SigmoidBackward>) tensor(1.) 0.18188020586967468\n",
      "tensor([0.4420], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.0504765510559082\n",
      "tensor([0.6109], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0332515686750412\n",
      "tensor([0.5408], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.11171519756317139\n",
      "tensor([0.3398], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.008065538480877876\n",
      "tensor([0.6423], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.12714783847332\n",
      "tensor([0.6670], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.1739245355129242\n",
      "tensor([0.4780], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.15758733451366425\n",
      "tensor([0.3851], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.07929655909538269\n",
      "tensor([0.5151], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.1396862268447876\n",
      "tensor([0.4409], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0034979975316673517\n",
      "tensor([0.3581], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.05849956348538399\n",
      "tensor([0.5042], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.1438094824552536\n",
      "tensor([0.4329], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.08413580060005188\n",
      "tensor([0.4814], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00034712013439275324\n",
      "tensor([0.5403], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.056373897939920425\n",
      "tensor([0.4619], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.01653299294412136\n",
      "tensor([0.3829], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.02642514742910862\n",
      "tensor([0.4402], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.0884302407503128\n",
      "tensor([0.5423], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.027997462078928947\n",
      "tensor([0.6180], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.06606197357177734\n",
      "tensor([0.4176], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.12970246374607086\n",
      "tensor([0.4737], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.03534451127052307\n",
      "tensor([0.4056], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.05009733885526657\n",
      "tensor([0.5668], grad_fn=<SigmoidBackward>) tensor(0.5714) 2.1575378923444077e-05\n",
      "tensor([0.5406], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.012555275112390518\n",
      "tensor([0.5132], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.007159338798373938\n",
      "tensor([0.5888], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.0013079459313303232\n",
      "tensor([0.5430], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.029323739930987358\n",
      "tensor([0.5869], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.020304063335061073\n",
      "tensor([0.5559], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.00024254880554508418\n",
      "tensor([0.4926], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.025352245196700096\n",
      "tensor([0.5807], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.08658412098884583\n",
      "tensor([0.5426], grad_fn=<SigmoidBackward>) tensor(1.) 0.20923396944999695\n",
      "tensor([0.3522], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.12098149955272675\n",
      "tensor([0.5511], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.047424010932445526\n",
      "tensor([0.6285], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.05228318274021149\n",
      "tensor([0.5525], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.0711693987250328\n",
      "tensor([0.4917], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.013609882444143295\n",
      "tensor([0.3911], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.008294064551591873\n",
      "tensor([0.4794], grad_fn=<SigmoidBackward>) tensor(1.) 0.2710739076137543\n",
      "tensor([0.5210], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.03735991567373276\n",
      "tensor([0.6688], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.000976312905550003\n",
      "tensor([0.4286], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.005103470757603645\n",
      "tensor([0.4462], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.002133231842890382\n",
      "tensor([0.4366], grad_fn=<SigmoidBackward>) tensor(0.4444) 6.188607221702114e-05\n",
      "tensor([0.5742], grad_fn=<SigmoidBackward>) tensor(0.5714) 7.783291039231699e-06\n",
      "tensor([0.5153], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.0031452253460884094\n",
      "tensor([0.6524], grad_fn=<SigmoidBackward>) tensor(1.) 0.12085770070552826\n",
      "tensor([0.4775], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.07423122972249985\n",
      "tensor([0.5779], grad_fn=<SigmoidBackward>) tensor(1.) 0.1781400889158249\n",
      "tensor([0.4229], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.04082903265953064\n",
      "tensor([0.4729], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.001963661750778556\n",
      "tensor([0.4440], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0002373039023950696\n",
      "tensor([0.6080], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.14883212745189667\n",
      "tensor([0.5272], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.13084284961223602\n",
      "tensor([0.4252], grad_fn=<SigmoidBackward>) tensor(0.0909) 0.11175765097141266\n",
      "tensor([0.4634], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.041311345994472504\n",
      "tensor([0.5236], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.12740278244018555\n",
      "tensor([0.4447], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.07267757505178452\n",
      "tensor([0.4292], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.04291359707713127\n",
      "tensor([0.3967], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.12478848546743393\n",
      "tensor([0.5312], grad_fn=<SigmoidBackward>) tensor(0.5385) 5.34208957105875e-05\n",
      "tensor([0.4632], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.045435041189193726\n",
      "tensor([0.6375], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.1237405464053154\n",
      "tensor([0.4713], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.009266046807169914\n",
      "tensor([0.5137], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.032540883868932724\n",
      "tensor([0.4402], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.02553718164563179\n",
      "tensor([0.5690], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.004766546189785004\n",
      "tensor([0.5578], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.15297187864780426\n",
      "tensor([0.6505], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.06272955238819122\n",
      "tensor([0.5184], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.008070983923971653\n",
      "tensor([0.5370], grad_fn=<SigmoidBackward>) tensor(0.1429) 0.15531501173973083\n",
      "tensor([0.6610], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.03846266493201256\n",
      "tensor([0.4283], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.005145434755831957\n",
      "tensor([0.6395], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.01220973115414381\n",
      "tensor([0.5713], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.005090104881674051\n",
      "tensor([0.7880], grad_fn=<SigmoidBackward>) tensor(1.) 0.04494645819067955\n",
      "tensor([0.3908], grad_fn=<SigmoidBackward>) tensor(1.) 0.37107643485069275\n",
      "tensor([0.4204], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.03927472233772278\n",
      "tensor([0.5332], grad_fn=<SigmoidBackward>) tensor(1.) 0.21791596710681915\n",
      "tensor([0.6203], grad_fn=<SigmoidBackward>) tensor(0.6250) 2.2434836864704266e-05\n",
      "tensor([0.3359], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.0556664802134037\n",
      "tensor([0.6104], grad_fn=<SigmoidBackward>) tensor(1.) 0.1517777442932129\n",
      "tensor([0.4858], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.0073261079378426075\n",
      "tensor([0.4562], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.007974140346050262\n",
      "tensor([0.4422], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.07593293488025665\n",
      "tensor([0.5857], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.0816439837217331\n",
      "tensor([0.4889], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.0681498795747757\n",
      "tensor([0.4501], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.06256066262722015\n",
      "tensor([0.5083], grad_fn=<SigmoidBackward>) tensor(1.) 0.2417789101600647\n",
      "tensor([0.6593], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.019802238792181015\n",
      "tensor([0.6717], grad_fn=<SigmoidBackward>) tensor(1.) 0.10779032111167908\n",
      "tensor([0.2039], grad_fn=<SigmoidBackward>) tensor(0.5625) 0.1286270022392273\n",
      "tensor([0.4393], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.03583059832453728\n",
      "tensor([0.3409], grad_fn=<SigmoidBackward>) tensor(0.3125) 0.0008076185476966202\n",
      "tensor([0.3346], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.027344955131411552\n",
      "tensor([0.7025], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.017125284299254417\n",
      "tensor([0.4266], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.057635702192783356\n",
      "tensor([0.2592], grad_fn=<SigmoidBackward>) tensor(0.2143) 0.0020143711008131504\n",
      "tensor([0.4376], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.09758850187063217\n",
      "tensor([0.7179], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.04748380184173584\n",
      "tensor([0.4090], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.0954764261841774\n",
      "tensor([0.4277], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.05709333345293999\n",
      "tensor([0.7360], grad_fn=<SigmoidBackward>) tensor(1.) 0.0697050616145134\n",
      "tensor([0.2648], grad_fn=<SigmoidBackward>) tensor(0.1875) 0.005968958139419556\n",
      "tensor([0.5991], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.029086658731102943\n",
      "tensor([0.3729], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.015101577155292034\n",
      "tensor([0.4455], grad_fn=<SigmoidBackward>) tensor(0.9091) 0.2149205207824707\n",
      "tensor([0.4193], grad_fn=<SigmoidBackward>) tensor(1.) 0.3372701406478882\n",
      "tensor([0.6866], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.04090733081102371\n",
      "tensor([0.5408], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.1000993400812149\n",
      "tensor([0.3755], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.0017755139851942658\n",
      "tensor([0.5406], grad_fn=<SigmoidBackward>) tensor(0.7273) 0.03486106917262077\n",
      "tensor([0.5133], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.05180273950099945\n",
      "tensor([0.4625], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.057731993496418\n",
      "tensor([0.3550], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.07915766537189484\n",
      "tensor([0.6432], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.005154759623110294\n",
      "tensor([0.2630], grad_fn=<SigmoidBackward>) tensor(0.4545) 0.03668540343642235\n",
      "tensor([0.3943], grad_fn=<SigmoidBackward>) tensor(0.4000) 3.1953983125276864e-05\n",
      "tensor([0.4731], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.049788638949394226\n",
      "tensor([0.4871], grad_fn=<SigmoidBackward>) tensor(0.9286) 0.19492840766906738\n",
      "tensor([0.3484], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.0039240699261426926\n",
      "tensor([0.4781], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.010638842359185219\n",
      "tensor([0.6573], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.014515459537506104\n",
      "tensor([0.6803], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.043488964438438416\n",
      "tensor([0.3952], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.19194640219211578\n",
      "tensor([0.4133], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.006399253383278847\n",
      "tensor([0.3467], grad_fn=<SigmoidBackward>) tensor(0.9167) 0.32491162419319153\n",
      "tensor([0.4239], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.05861556902527809\n",
      "tensor([0.4194], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.02311992458999157\n",
      "tensor([0.2687], grad_fn=<SigmoidBackward>) tensor(0.1333) 0.018329337239265442\n",
      "tensor([0.6172], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.04669613391160965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6948], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.004876620136201382\n",
      "tensor([0.5780], grad_fn=<SigmoidBackward>) tensor(1.) 0.1780555248260498\n",
      "tensor([0.6402], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.012057933956384659\n",
      "tensor([0.4516], grad_fn=<SigmoidBackward>) tensor(1.) 0.30076849460601807\n",
      "tensor([0.3856], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.02888191118836403\n",
      "tensor([0.4794], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.014540065079927444\n",
      "tensor([0.4137], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0002222898037871346\n",
      "tensor([0.5280], grad_fn=<SigmoidBackward>) tensor(0.7692) 0.058215126395225525\n",
      "tensor([0.5819], grad_fn=<SigmoidBackward>) tensor(1.) 0.17477142810821533\n",
      "tensor([0.5996], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.04014198109507561\n",
      "tensor([0.5477], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.0886189341545105\n",
      "tensor([0.5101], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.00010122064122697338\n",
      "tensor([0.6002], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.08334320783615112\n",
      "tensor([0.4639], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.04110095277428627\n",
      "tensor([0.6804], grad_fn=<SigmoidBackward>) tensor(0.7273) 0.0022000661119818687\n",
      "tensor([0.2593], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.005483249202370644\n",
      "tensor([0.4246], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.03077094815671444\n",
      "tensor([0.4222], grad_fn=<SigmoidBackward>) tensor(0.9091) 0.2370489239692688\n",
      "tensor([0.3791], grad_fn=<SigmoidBackward>) tensor(0.1818) 0.03893176466226578\n",
      "tensor([0.5961], grad_fn=<SigmoidBackward>) tensor(0.7273) 0.017213286831974983\n",
      "tensor([0.3453], grad_fn=<SigmoidBackward>) tensor(0.1538) 0.03667038679122925\n",
      "tensor([0.7573], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.009965178556740284\n",
      "tensor([0.4131], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.044880516827106476\n",
      "tensor([0.6536], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.021434122696518898\n",
      "tensor([0.6087], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.028585532680153847\n",
      "tensor([0.3763], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.07636864483356476\n",
      "tensor([0.5416], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.058359865099191666\n",
      "tensor([0.5120], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.018758784979581833\n",
      "tensor([0.4899], grad_fn=<SigmoidBackward>) tensor(0.8182) 0.10775439441204071\n",
      "tensor([0.4345], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.014666554518043995\n",
      "tensor([0.4419], grad_fn=<SigmoidBackward>) tensor(0.5833) 0.020003698766231537\n",
      "tensor([0.4101], grad_fn=<SigmoidBackward>) tensor(0.4167) 4.282697773305699e-05\n",
      "tensor([0.6745], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.001584053272381425\n",
      "tensor([0.6832], grad_fn=<SigmoidBackward>) tensor(0.9000) 0.04700884595513344\n",
      "tensor([0.3606], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.05549616739153862\n",
      "tensor([0.3327], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.049088768661022186\n",
      "tensor([0.3622], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.026308758184313774\n",
      "tensor([0.6186], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.00034505987423472106\n",
      "tensor([0.5438], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.024410970509052277\n",
      "tensor([0.5345], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.008113868534564972\n",
      "tensor([0.3819], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.06599576026201248\n",
      "tensor([0.4319], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.004644184838980436\n",
      "tensor([0.5501], grad_fn=<SigmoidBackward>) tensor(1.) 0.20241008698940277\n",
      "tensor([0.5475], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.06123235449194908\n",
      "tensor([0.5671], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.10057085007429123\n",
      "tensor([0.4260], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.07508464902639389\n",
      "tensor([0.5909], grad_fn=<SigmoidBackward>) tensor(1.) 0.16733944416046143\n",
      "tensor([0.5210], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.052455075085163116\n",
      "tensor([0.6606], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.067906454205513\n",
      "tensor([0.4125], grad_fn=<SigmoidBackward>) tensor(0.1250) 0.08267311006784439\n",
      "tensor([0.5753], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.005677413661032915\n",
      "tensor([0.6220], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.04928560182452202\n",
      "tensor([0.4870], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.09796815365552902\n",
      "tensor([0.6123], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.05632103979587555\n",
      "tensor([0.5432], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.028292328119277954\n",
      "tensor([0.4726], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.0349121019244194\n",
      "tensor([0.4288], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.137780100107193\n",
      "tensor([0.5041], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.11384247243404388\n",
      "tensor([0.4336], grad_fn=<SigmoidBackward>) tensor(0.4286) 2.566231705714017e-05\n",
      "tensor([0.4102], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.22910308837890625\n",
      "tensor([0.5843], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.0001644794101594016\n",
      "tensor([0.4684], grad_fn=<SigmoidBackward>) tensor(1.) 0.28263747692108154\n",
      "tensor([0.5820], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.02353314310312271\n",
      "tensor([0.6093], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.011021587066352367\n",
      "tensor([0.3373], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.018843336030840874\n",
      "tensor([0.6570], grad_fn=<SigmoidBackward>) tensor(0.8571) 0.04005778580904007\n",
      "tensor([0.5781], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.000506077369209379\n",
      "tensor([0.4152], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.006702509708702564\n",
      "tensor([0.5022], grad_fn=<SigmoidBackward>) tensor(0.8889) 0.14950469136238098\n",
      "tensor([0.5687], grad_fn=<SigmoidBackward>) tensor(0.6000) 0.0009826889727264643\n",
      "tensor([0.3558], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.017840204760432243\n",
      "tensor([0.6018], grad_fn=<SigmoidBackward>) tensor(0.5556) 0.0021346472203731537\n",
      "tensor([0.3575], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.001805853913538158\n",
      "tensor([0.4777], grad_fn=<SigmoidBackward>) tensor(0.7778) 0.09004873782396317\n",
      "tensor([0.4703], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.061553165316581726\n",
      "tensor([0.5337], grad_fn=<SigmoidBackward>) tensor(0.2222) 0.09704332053661346\n",
      "tensor([0.3031], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.15756474435329437\n",
      "tensor([0.5880], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.22739703953266144\n",
      "tensor([0.5090], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.09545500576496124\n",
      "tensor([0.5224], grad_fn=<SigmoidBackward>) tensor(0.9000) 0.1426142305135727\n",
      "tensor([0.5026], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.005480769090354443\n",
      "tensor([0.4814], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.03829741105437279\n",
      "tensor([0.3700], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.07288917899131775\n",
      "tensor([0.5770], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.029916660860180855\n",
      "tensor([0.5230], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.006163616664707661\n",
      "tensor([0.6549], grad_fn=<SigmoidBackward>) tensor(1.) 0.11912576109170914\n",
      "tensor([0.6655], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.0011911345645785332\n",
      "tensor([0.4451], grad_fn=<SigmoidBackward>) tensor(0.4444) 3.979411360433005e-07\n",
      "tensor([0.5394], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.030571620911359787\n",
      "tensor([0.4440], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.02506200782954693\n",
      "tensor([0.5917], grad_fn=<SigmoidBackward>) tensor(0.8333) 0.058377258479595184\n",
      "tensor([0.5314], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.000985239283181727\n",
      "tensor([0.4543], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.028406847268342972\n",
      "tensor([0.3639], grad_fn=<SigmoidBackward>) tensor(0.9000) 0.2874561548233032\n",
      "tensor([0.6490], grad_fn=<SigmoidBackward>) tensor(0.5714) 0.006013086531311274\n",
      "tensor([0.4034], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.0008087725145742297\n",
      "tensor([0.4723], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.023310692980885506\n",
      "tensor([0.6986], grad_fn=<SigmoidBackward>) tensor(0.8750) 0.03111938014626503\n",
      "tensor([0.5128], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0001640760456211865\n",
      "tensor([0.6021], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.003206310560926795\n",
      "tensor([0.3936], grad_fn=<SigmoidBackward>) tensor(0.4286) 0.0012246284168213606\n",
      "tensor([0.3594], grad_fn=<SigmoidBackward>) tensor(1.) 0.4103720486164093\n",
      "tensor([0.4035], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.09212473034858704\n",
      "tensor([0.7083], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.17861464619636536\n",
      "tensor([0.3876], grad_fn=<SigmoidBackward>) tensor(0.6250) 0.056377749890089035\n",
      "tensor([0.5685], grad_fn=<SigmoidBackward>) tensor(0.6364) 0.004610863514244556\n",
      "tensor([0.4196], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.006463027559220791\n",
      "tensor([0.4579], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0017710713436827064\n",
      "tensor([0.6328], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.017640000209212303\n",
      "tensor([0.3857], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.04795975983142853\n",
      "tensor([0.3744], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.043162617832422256\n",
      "tensor([0.3878], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.048916351050138474\n",
      "tensor([0.3914], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.09492846578359604\n",
      "tensor([0.5689], grad_fn=<SigmoidBackward>) tensor(0.0833) 0.23582099378108978\n",
      "tensor([0.5246], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.020191455259919167\n",
      "tensor([0.4408], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.09561064094305038\n",
      "tensor([0.5637], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.03471783176064491\n",
      "tensor([0.3812], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.04604152590036392\n",
      "tensor([0.2678], grad_fn=<SigmoidBackward>) tensor(0.1667) 0.010230489075183868\n",
      "tensor([0.2998], grad_fn=<SigmoidBackward>) tensor(0.3000) 3.664173675588245e-08\n",
      "tensor([0.3289], grad_fn=<SigmoidBackward>) tensor(0.3000) 0.0008343694498762488\n",
      "tensor([0.5596], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.025484371930360794\n",
      "tensor([0.5686], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.055347539484500885\n",
      "tensor([0.4412], grad_fn=<SigmoidBackward>) tensor(0.8000) 0.12876322865486145\n",
      "tensor([0.5208], grad_fn=<SigmoidBackward>) tensor(0.4000) 0.014598009176552296\n",
      "tensor([0.6168], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.17370551824569702\n",
      "tensor([0.4814], grad_fn=<SigmoidBackward>) tensor(0.7500) 0.07215762138366699\n",
      "tensor([0.3051], grad_fn=<SigmoidBackward>) tensor(0.3636) 0.0034228453878313303\n",
      "tensor([0.7414], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.20763452351093292\n",
      "tensor([0.3517], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.010338709689676762\n",
      "tensor([0.7767], grad_fn=<SigmoidBackward>) tensor(0.7143) 0.0038976268842816353\n",
      "tensor([0.3507], grad_fn=<SigmoidBackward>) tensor(0.1111) 0.057389453053474426\n",
      "tensor([0.5791], grad_fn=<SigmoidBackward>) tensor(0.7000) 0.014620883390307426\n",
      "tensor([0.7510], grad_fn=<SigmoidBackward>) tensor(1.) 0.06199299171566963\n",
      "tensor([0.3738], grad_fn=<SigmoidBackward>) tensor(0.2000) 0.0302009005099535\n",
      "tensor([0.3606], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.06791408360004425\n",
      "tensor([0.3908], grad_fn=<SigmoidBackward>) tensor(0.6667) 0.07609020918607712\n",
      "tensor([0.4771], grad_fn=<SigmoidBackward>) tensor(0.4444) 0.0010644755093380809\n",
      "tensor([0.6804], grad_fn=<SigmoidBackward>) tensor(0.5455) 0.0181974396109581\n",
      "tensor([0.5242], grad_fn=<SigmoidBackward>) tensor(0.5000) 0.0005868158186785877\n",
      "tensor([0.4673], grad_fn=<SigmoidBackward>) tensor(0.0909) 0.14165934920310974\n",
      "tensor([0.4296], grad_fn=<SigmoidBackward>) tensor(0.2500) 0.03226463869214058\n",
      "tensor([0.4372], grad_fn=<SigmoidBackward>) tensor(0.1000) 0.11370495706796646\n",
      "tensor([0.7031], grad_fn=<SigmoidBackward>) tensor(0.3750) 0.10767403244972229\n",
      "tensor([0.6650], grad_fn=<SigmoidBackward>) tensor(0.2857) 0.14388597011566162\n",
      "tensor([0.5294], grad_fn=<SigmoidBackward>) tensor(0.3333) 0.03844383731484413\n"
     ]
    }
   ],
   "source": [
    "loaded_model = torch.load('./models/linear-model-8e-20190501.pth')\n",
    "\n",
    "# Evaluate model\n",
    "loaded_model = loaded_model.to(device)\n",
    "model.eval()\n",
    "element = 98\n",
    "\n",
    "for element in range(0, len(test_data)):\n",
    "    if element % 10 == 0:\n",
    "        data = torch.tensor(test_data.iloc[element,:-1]).to(device)\n",
    "        label = torch.tensor(test_data.iloc[element, -1]).to(device)\n",
    "\n",
    "        prediction = loaded_model(data)\n",
    "        loss = criterion(prediction, label)\n",
    "\n",
    "        print(prediction, label, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:julie-stav-ws]",
   "language": "python",
   "name": "conda-env-julie-stav-ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
